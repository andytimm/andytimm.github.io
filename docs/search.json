[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Andy Timm",
    "section": "",
    "text": "I always learn a ton about people’s interests by hearing about what projects they’re excited about. If you’re working on similar things, and want to talk about them more or learn together, I’m always excited to chat (especially if you’re doing the work for social good)!\nHere are some current work and personal projects I’m particularly excited about:\n\n\n\nPersonal Projects\n\nUpskilling on Variational Inference: with a particular focus on techniques like normalizing flows which improve our ability to correctly quantify uncertainty 1.\nStudying Declining US Social Capital: Building a better knowledge base on declining social capital in the US, and the implications of this, especially for politics2.\nLearning more about Effective Altruism: especially longtermism, and evaluating how interested I am becoming more involved in the community3.\n\n\n\n\nWork Projects\n\nBetter Polling Methods: Improving our political survey methodology choices to improve our resulting model quality in the 2022 midterm elections4.\nProductizing HTE Estimation: Exploring which Heterogeneous Treatment Effect models perform best in our industry in a variety of contexts, with an eye towards a fully productized solution in early 20235.\nBetter CI’s when Identification is Weak: Improving our uncertainty quantification when using observational methods with weaker identification strategies6.\n\n\nI also want to start building out a broader list of topics that I’ve spent time with or want to do a deeper dive in. For example, last winter I spent a ton of time exploring Potential Outcome vs DAG approaches to causal inference. In grad school I was particularly focused on the effects of educational polarization in the US, etc. As a future example, I want to do a broader dive into how social media effects culture and politics. This is both a personal thing (to track what I’ve been interested in over the years), and a social one (I love sharing resources and working with others to learn these topics).\n\n\n\n\n\nFootnotes\n\n\nI started this out by working through Depth First Learning’s Variational Inference with Normalizing Flows curriculum. Next, I plan to implement a couple of MRP models with various flavors of VI, and see how it holds up to a MCMC version.↩︎\nFor this, I’m reading some of Putnam’s work since Bowling Alone, and a bunch of papers in the vein of this Nature paper.↩︎\nHaving read WWOTF, I’m now reading The Precipice and plan to read Doing Good Better. In addition, reading a bunch of the EA Forum. Since I already think about maximizing my social impact, there are a lot of appealing ideas here. I have two cruxes here: first, I’m not sure if I trust EA’s commitment to being non-political- as laid out here and here. Second, I’m not yet sure I buy the math behind the heavy focus on existential risk causes.↩︎\nNone of these links will get at any IP, but broadly I’m synthesizing a lot of what I learned from AAPOR 2022 (this thread is a good starting point) and examining how some decent ideas would’ve changed our recent predictions.↩︎\nThere are a ton of ideas to explore here, but some of the most promising are double/debiased ML estimators, Meta Learners, and other ideas explored in recent ACIC competitions.↩︎\nIf we’re trying to estimate a causal effect without an experiment or believable instrument, and have to rely on covariate adjustment-esque strategies, how can we quantify our uncertainty? Can we reason about plausible sizes of unobserved confounders and in so doing move the discussion past “you needed to control for U”? If we can make such claims, can we use them to then define uncertainty intervals which reflect our various levels of plausibility for such concerns?↩︎"
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software",
    "section": "",
    "text": "Most of the cool stuff I get to build these days isn’t public unfortunately. Hoping to expand out my public stuff eventually, but I do have an R package that gets some use:"
  },
  {
    "objectID": "software.html#retrodesign",
    "href": "software.html#retrodesign",
    "title": "Software",
    "section": "retrodesign",
    "text": "retrodesign\nretrodesign provides tools for working with Type S (Sign) and Type M (Magnitude) errors, as proposed in Gelman and Tuerlinckx (2000) and Gelman & Carlin (2014). In addition to simply calculating the probability of Type S/M error, the package includes functions for calculating these errors across a variety of effect sizes for comparison, and recommended sample size given “tolerances” for Type S/M errors. To improve the speed of these calculations, closed forms solutions for the probability of a Type S/M error from Lu, Qiu, and Deng (2018) are implemented. The broader goal of this project was to make it easier for researchers to understand these issues in their work, and it’s gratifying the package has been able to do that.\n\n        \n        Website\n     \n        \n        Github\n     \n        \n        Package"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Rarely Updated Blog",
    "section": "",
    "text": "Andy Timm\n\n\n\n\n\n\n  \n\n\n\n\nVariational Inference for MRP with Reliable Posterior Distributions\n\n\nIntroductions- things to do, places to be\n\n\n\n\nMRP\n\n\nBART\n\n\nVariational Inference\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2022\n\n\nAndy Timm\n\n\n\n\n\n\n  \n\n\n\n\nBART with varying intercepts in the MRP framework\n\n\n\n\n\n\n\nFrom Old Website\n\n\nMRP\n\n\nBART\n\n\n\n\n\n\n\n\n\n\n\nJul 3, 2019\n\n\nAndy Timm\n\n\n\n\n\n\n  \n\n\n\n\nConvention Prediction with a Bayesian Hierarchical Multinomial Model\n\n\n\n\n\n\n\nFrom Old Website\n\n\nStan\n\n\n\n\n\n\n\n\n\n\n\nJul 3, 2019\n\n\nAndy Timm\n\n\n\n\n\n\n  \n\n\n\n\nIs Voting Habit Forming? Replication, and additional robustness checks\n\n\n\n\n\n\n\nFrom Old Website\n\n\ncausal inference\n\n\n\n\n\n\n\n\n\n\n\nJul 3, 2019\n\n\nAndy Timm\n\n\n\n\n\n\n  \n\n\n\n\nType S/M errors in R with retrodesign()\n\n\n\n\n\n\n\nFrom Old Website\n\n\n\n\n\n\n\n\n\n\n\nMay 11, 2018\n\n\nAndy Timm\n\n\n\n\n\n\n  \n\n\n\n\nWhy the normal distribution?\n\n\n\n\n\n\n\nFrom Old Website\n\n\n\n\n\n\n\n\n\n\n\nMay 11, 2018\n\n\nAndy Timm\n\n\n\n\n\n\n  \n\n\n\n\nPredicting race part 1- Bayes’ rule method and extensions\n\n\n\n\n\n\n\nFrom Old Website\n\n\n\n\n\n\n\n\n\n\n\nApr 10, 2018\n\n\nAndy Timm\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Andy Timm",
    "section": "",
    "text": "About\nI’m currently a Manager of Data Science at 605, where I work on problems of observational inference and persuadability modeling, helping our corporate and political clients to better understand the impact of their advertising campaigns and optimize their targeting. Previously, I was a grad student at NYU Gallatin, where I was lucky to have the freedom to study a wide variety of topics in political science, statistics, and data science.\nMethodologically, I am passionate about quantifying uncertainty in observational inference; when we work on the many essential political and business questions that cannot be approached with experiments, how do we rigorously understand the uncertainty and limitations that come with observational methods? Some of my substantive interests include the increasing prominence of white identity in American politics, and the extent to which voting is habit forming.\nBefore grad school, I was a field and data staffer up and down the ballot in Minnesota. When not thinking about politics, I can most often be found running, reading, or playing chess.\nMy aim with this space is to show off some of my larger side projects, especially those that would benefit from some expository writing. I’ll also include occasional career updates.\nThis new website is still very much a WIP. Thanks to Drew Dimmery for starting point for this and post on how to make a quick Quarto website!\n\n    \n\n\n\n    \n\n\n\n    \n\n\n\n    \n\n\n\n\n\n\n\nMy Bookshelf as of September 2022. Hopefully more useful than squinting on zoom!"
  }
]