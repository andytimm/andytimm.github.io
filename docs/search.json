[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Andy Timm",
    "section": "",
    "text": "I always learn a ton about people’s interests by hearing about what projects they’re excited about. If you’re working on similar things, and want to talk about them more or learn together, I’m always excited to chat (especially if your application helps people)!\nHere are some current personal and personal projects I’m particularly excited about:\n\n\n\nPersonal Projects\n\nScalable Bayesian Inference: What flavors and augmentations of variational inference allow us to most flexibly and reliably scale Bayesian inference to large datasets? Are there other viable tools for scalable Bayes that are less explored? 1.\nModern Survey Experiment Designs: As high quality survey completes grow ever more expensive, can tools like discrete choice models or conjoint experiments more efficiently approximate the same learnings? How can we tell when these methods will and won’t produce the same findings as experiments? 2.\nHow Media Shapes Politics: How do Social Media and TV as platforms shape US Politics? How harmful are they to society in terms of polarization, if at all?3.\n\n\n\n\nWork Projects\n\nStrategy Given Causal Uncertainty: Media planning decision makers’ need for analytical guidance constantly outstrips their ability to generate deeply-grounded causal knowledge. Given we will never have all the causal information we desire, how do we provide actionable guidance that proves out its value when acted upon?4.\nHierarchical Forecasting for Media Planning: Being able to accurately forecast the likely reach of a media plan at a variety of granularities enables better planning; what are the most reliable and accurate forecasting models for our applications? 5.\nProductizing HTE Estimation: Exploring which heterogeneous treatment effect models perform best in our industry in a variety of contexts, with a fully productized solution coming online as of early 20236.\n\n\nI also want to start building out a broader list of topics that I’ve spent time with or want to do a deeper dive in. For example, last winter I spent a ton of time exploring Potential Outcome vs DAG approaches to causal inference. In grad school I was particularly focused on the effects of educational polarization in the US, etc. As a future example, I want to do a broader dive into how social media effects culture and politics. This is both a personal thing (to track what I’ve been interested in over the years), and a social one (I love sharing resources and working with others to learn these topics).\n\n\n\n\n\nFootnotes\n\n\nThere are lots of applications in which I’d prefer a Bayesian model, but where scaling them is simply impractical or unreliable. I started learning more here this out by working through Depth First Learning’s Variational Inference with Normalizing Flows curriculum. To explore more tools in this area, I’m writing a blog post series where I try to get reasonable variational approximations posterior distributions for a basic MRP model, exploring the literature on various flavors and augmentations of VI and diagnostic techniques along the way. I’m particularly excited about normalizing flows-based approaches based on past successes I’ve had in other work. I am also absolutely fascinated by work like Hoffman and Ma (2020) that show Black Box VI actually follows a similar gradient flow to some forms of MCMC, with the resulting algorithmic suggestion that many short chains averaged may be another reasonable formula for scalable Bayes; in practice, I haven’t seen this outperform VI, but would love to see any counter examples!↩︎\nI’m inspired here by Data for Progress/Priorities USA’s testing around replacing in-survey RCTs with a MaxDiff/Best-Worst Scaling deisgn on the discrete choice side. Commonsense Solidarity is a similar inspiration in terms of conjoint experiments that can provide huge amounts of information efficiently. To learn more here, several of the chapters in Advances in Experimental Political Science have been a fantastic starting point for me. Working in advertising where discrete choice modelers commonly rely on Sawtooth, I’ve been thinking about strange contradictions of how it implements MaxDiff ; Jim Savage’s notes and Stan Forum comments here have been super helpful, and I’m working on building Stan implementations of both what Sawtooth chooses to do and the perhaps more reasonable ranked choice random coefficients implementation for the bwsTools R package to get more hands on here.↩︎\nThe rough intuition I have here as someone working in TV is that Social Media gets a lot of hype about how it negatively shapes politics, but if anything, TV is much more likely to be the impactful platform platform. Robert Putnam famously theorizes that television is and was responsible for 20% of the recent decay in American social capital; how plausible is that? To see if that intuition is supported by research, I’m working through reading the papers and books mentioned in Chris Bail’s Social Media and Political Dysfunction Collaborative Review, and working on finding similar books and papers that ask the same questions of television.↩︎\nIn advertising in general, but especially TV, we can never have as many experiments as we’d like when making decisions; for example, the CPMs of addressable TV rule out an experiment at all but a handful of decision points. How then do we help clients make the most of the experiments they can run, and integrate everything from rigorously obtained causal knowledge to quasi-experimental studies to simple predictive models to make media planning decisions? Some of the most sophisticated and exciting work in this space looks like Lyft’s Causal Forecasting, but for many clients this is worlds away from current practice. Given much of the modern TV industry developed its intuitions here before the credibility revolutions in statistics and the social sciences, how do combat a strongly exaggerated sense of what should be possible to know given certain data while still meeting client needs?↩︎\nBy forecasting reach and impressions of a proposed media plan at any level from coarse network-daypart combinations all the way down to individual household likelihoods of viewing a placed ad, our clients can adjust their plans to meet their goals. Of course, different granularities of forecast are orders of magnitude apart in difficulty and resulting accuracy expectations; how do we combine them into a stronger, coherent picture? Without getting too close to IP, our solution relies on Bayesian time series models that are then reconciled using hierarchical forecasting technqiues to maximize accuracy at all levels.↩︎\nThere are a ton of ideas to explore here, but some of the most promising are double/debiased ML estimators, Meta Learners, and other ideas explored in recent ACIC competitions.↩︎"
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software",
    "section": "",
    "text": "Most of the cool stuff I get to build these days isn’t public unfortunately. Hoping to expand out my public stuff eventually, but I do have an R package that gets some use:"
  },
  {
    "objectID": "software.html#retrodesign",
    "href": "software.html#retrodesign",
    "title": "Software",
    "section": "retrodesign",
    "text": "retrodesign\nretrodesign provides tools for working with Type S (Sign) and Type M (Magnitude) errors, as proposed in Gelman and Tuerlinckx (2000) and Gelman & Carlin (2014). In addition to simply calculating the probability of Type S/M error, the package includes functions for calculating these errors across a variety of effect sizes for comparison, and recommended sample size given “tolerances” for Type S/M errors. To improve the speed of these calculations, closed forms solutions for the probability of a Type S/M error from Lu, Qiu, and Deng (2018) are implemented. The broader goal of this project was to make it easier for researchers to understand these issues in their work, and it’s gratifying the package has been able to do that.\n\n        \n        Website\n     \n        \n        Github\n     \n        \n        Package"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Rarely Updated Blog",
    "section": "",
    "text": "Andy Timm\n\n\n\n\n\n\n  \n\n\n\n\nVariational Inference for MRP with Reliable Posterior Distributions\n\n\nPart 2- The errors of our ways\n\n\n\n\nMRP\n\n\nVariational Inference\n\n\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\nAndy Timm\n\n\n\n\n\n\n  \n\n\n\n\nVariational Inference for MRP with Reliable Posterior Distributions\n\n\nIntroductions- things to do, places to be\n\n\n\n\nMRP\n\n\nBART\n\n\nVariational Inference\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2022\n\n\nAndy Timm\n\n\n\n\n\n\n  \n\n\n\n\nBART with varying intercepts in the MRP framework\n\n\n\n\n\n\n\nFrom Old Website\n\n\nMRP\n\n\nBART\n\n\n\n\n\n\n\n\n\n\n\nJul 3, 2019\n\n\nAndy Timm\n\n\n\n\n\n\n  \n\n\n\n\nConvention Prediction with a Bayesian Hierarchical Multinomial Model\n\n\n\n\n\n\n\nFrom Old Website\n\n\nStan\n\n\n\n\n\n\n\n\n\n\n\nJul 3, 2019\n\n\nAndy Timm\n\n\n\n\n\n\n  \n\n\n\n\nIs Voting Habit Forming? Replication, and additional robustness checks\n\n\n\n\n\n\n\nFrom Old Website\n\n\ncausal inference\n\n\n\n\n\n\n\n\n\n\n\nJul 3, 2019\n\n\nAndy Timm\n\n\n\n\n\n\n  \n\n\n\n\nType S/M errors in R with retrodesign()\n\n\n\n\n\n\n\nFrom Old Website\n\n\n\n\n\n\n\n\n\n\n\nMay 11, 2018\n\n\nAndy Timm\n\n\n\n\n\n\n  \n\n\n\n\nWhy the normal distribution?\n\n\n\n\n\n\n\nFrom Old Website\n\n\n\n\n\n\n\n\n\n\n\nMay 11, 2018\n\n\nAndy Timm\n\n\n\n\n\n\n  \n\n\n\n\nPredicting race part 1- Bayes’ rule method and extensions\n\n\n\n\n\n\n\nFrom Old Website\n\n\n\n\n\n\n\n\n\n\n\nApr 10, 2018\n\n\nAndy Timm\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Andy Timm",
    "section": "",
    "text": "About\nI’m currently a Manager of Data Science at 605, where I work on problems of causal inference, forecasting, and persuadability modeling, helping our corporate and political clients to better understand the impact of their advertising campaigns and optimize their targeting. Previously, I was a grad student at NYU Gallatin, where I was lucky to have the freedom to study a wide variety of topics in political science, statistics, and computer science.\nA core theme of my methodological work is how to integrate casual learnings of varying quality into larger decision making models; I share some examples of this on my projects page. Some of my substantive interests include the increasing prominence of white identity in American politics, and the extent to which voting is habit forming.\nBefore grad school, I was a field and data staffer up and down the ballot in Minnesota. When not thinking about politics, I can most often be found running, reading, or playing chess.\nMy aim with this space is to show off some of my larger side projects, especially those that would benefit from some expository writing. I’ll also include occasional career updates.\nThis new website is still very much a WIP. Thanks to Drew Dimmery for starting point for this and post on how to make a quick Quarto website!\n\n    \n\n\n\n    \n\n\n\n    \n\n\n\n    \n\n\n\n\n\n\n\nMy Bookshelf as of January 2023. Hopefully more useful than squinting on zoom!"
  },
  {
    "objectID": "posts/Variational MRP Pt1/variational_mrp_pt1.html",
    "href": "posts/Variational MRP Pt1/variational_mrp_pt1.html",
    "title": "Variational Inference for MRP with Reliable Posterior Distributions",
    "section": "",
    "text": "This post introduces a series I intend to write, exploring using Variational Inference to massively speed up running complex survey estimation models like variants of Multilevel Regression and Poststratification while aiming to keep approximation error from completely ruining the model.\nThe rough plan for the series is as follows:"
  },
  {
    "objectID": "posts/Variational MRP Pt1/variational_mrp_pt1.html#introducing-mrp",
    "href": "posts/Variational MRP Pt1/variational_mrp_pt1.html#introducing-mrp",
    "title": "Variational Inference for MRP with Reliable Posterior Distributions",
    "section": "Introducing MRP",
    "text": "Introducing MRP\nWhile I’m mostly focused on the way we choose to actually fit a given model with this series, here’s a super quick review of the intuition in building a MRP model. If you want a more complete introduction, Kastellec’s MRP Primer is a great starting point, as are the case studies I link a bit later.\nMRP casts estimation of a population quantity of interest \\theta as a prediction problem. That is, instead of the more traditional approach of building simple raked weights and using weighted estimators, MRP leans more heavily on modeling and then poststratification to make the estimates representative.\nTo sketch out the steps-\n\nEither gather or run a survey or collection of surveys that collect both information on the outcome of interest, y, and a set of demographic and geographic predictors, \\left(X_{1}, X_{2}, X_{3}, \\ldots, X_{m}\\right).\nBuild a poststratification table, with population counts or estimated population counts N_{j} for each possible combination of the features gathered above. Each possible combination j is called a cell, one of J possible cells. For example, if we poststratified only on state, there would be J=51 (with DC) total cells; in practice, J is often several thousand.\nBuild a model, usually a Bayesian multilevel regression, to predict y using the demographic characteristic from the survey or set of surveys, estimating model parameters along the way.\nEstimate y for each cell in the poststratification table, using the model built on the sample.\nAggregate the cells to the population of interest, weighting by the N_{j}’s to obtain population level estimates: \\theta_{\\mathrm{POP}}=\\frac{\\sum_{j \\in J} N_{j} \\theta_{j}}{\\sum_{j \\in J} N_{J}}\n\nWhy would we want to do this over building more typical survey weights? To the extent your new model has desirable properties like the ability to incorporate priors, can partially pool to manage rare subpopulations where you don’t have a lot of sample, and so on, you can get the benefits of that more efficient model through MRP. Raking in its simplest form is really just a linear model; we have plenty of methods that can do better. Outside of bayesian multilevel models which are the most common, there’s an increasing literature on using a wide variety of machine learning algorithms like BART2 to do the estimation stage; Andrew Gelman calls this RRP."
  },
  {
    "objectID": "posts/Variational MRP Pt1/variational_mrp_pt1.html#introducing-the-running-example",
    "href": "posts/Variational MRP Pt1/variational_mrp_pt1.html#introducing-the-running-example",
    "title": "Variational Inference for MRP with Reliable Posterior Distributions",
    "section": "Introducing the Running Example",
    "text": "Introducing the Running Example\nRather than reinvent the wheel, I’ll follow the lead of the excellent Multilevel Regression and Poststratification Case Studies by Lopez-Martin, Philips, and Gelman, and model survey binary responses from the 2018 CCES for the following question:\n\nAllow employers to decline coverage of abortions in insurance plans (Support / Oppose)\n\nFrom the CCES, we get information on each participant’s state, age, gender, ethnicity, and education level. Supplementing this individual level data, we also include region flags for each state, and Republican vote share in the 2016 election- these state level predictors have been shown to be critical for getting strong MRP estimates by Lax and Philips (2009) and others. and If you’d like deeper detail on the dataset itself, I’d refer you to this part MRP case study.\nUsing these, we setup the model for Pr(y_i = 1) the probability of supporting allowing employers to decline coverage of abortions in insurance plans as:\n\n\\begin{aligned}\nPr(y_i = 1) =& logit^{-1}(\n\\gamma^0\n+ \\alpha_{\\rm s[i]}^{\\rm state}\n+ \\alpha_{\\rm a[i]}^{\\rm age}\n+ \\alpha_{\\rm r[i]}^{\\rm eth}\n+ \\alpha_{\\rm e[i]}^{\\rm educ}\n+ \\beta^{\\rm male} \\cdot {\\rm Male}_{\\rm i} \\\\\n&+ \\alpha_{\\rm g[i], r[i]}^{\\rm male.eth}\n+ \\alpha_{\\rm e[i], a[i]}^{\\rm educ.age}\n+ \\alpha_{\\rm e[i], r[i]}^{\\rm educ.eth}\n+ \\gamma^{\\rm south} \\cdot {\\rm South}_{\\rm s} \\\\\n&+ \\gamma^{\\rm northcentral} \\cdot {\\rm NorthCentral}_{\\rm s}\n+ \\gamma^{\\rm west} \\cdot {\\rm West}_{\\rm s}\n+ \\gamma^{\\rm repvote} \\cdot {\\rm RepVote}_{\\rm s})\n\\end{aligned}\n\nWhere we incorporate pretty much all of our predictors as varying intercepts to allow for pooling across demographic and geographic characteristics:\n\n\\alpha_{\\rm a}^{\\rm age}: The effect of subject i’s age on the probability of supporting the statement.\n\\alpha_{\\rm r}^{\\rm eth}: The effect of subject i’s ethnicity on the probability of supporting the statement.\n\\alpha_{\\rm e}^{\\rm educ}: The effect of subject i’s education on the probability of supporting the statement.\n\\alpha_{\\rm s}^{\\rm state}: The effect of subject i’s state on the probability of supporting the statement.\n\\beta^{\\rm male}: The average effect of being male on the probability of supporting abortion. Note that it doesn’t really make much sense to model a two category3 factor as a varying intercept.\n\\alpha_{\\rm e,r}^{\\rm male.eth}, \\alpha_{\\rm e,r}^{\\rm educ.age}, \\alpha_{\\rm e,r}^{\\rm educ.eth}: Are several reasonable guesses at important interactions for this question. We could add many more two way, or even some three way interactions here, but this is enough for my testing here.\n\\gamma^{\\rm south}, \\gamma^{\\rm northcentral}, \\gamma^{\\rm west},\\gamma^{\\rm repvote}: are the state level predictors which are not represented as varying intercepts. Following the case study, I use \\gamma’s for the state level coefficients, keeping \\beta’s for individual coefficients. Note that Northeast is the base region of the region factor here, so it doesn’t get it’s own coefficient.\n\nStepping back for a second, let’s describe the complexity of this model in more general terms. This certainly isn’t state of the art for MRP, and you could definitely add in things like a lot more interactions, some varying slopes, non-univariate prior and/or structured priors, or other elements to make this a more interesting model. That said, this is already clearly enough of a model to improve on simple raking in many cases, and it produces a nuanced enough posterior that we can feasibly imagine a bad approximation going all spherical cow shaped on us.\nWhy this dataset and this model for this series? The question we model itself isn’t super important- as long as we can expect some significant regional and demographic variation in the outcome we’ll be able to explore if VI smoothes away some posterior complexity that MCMC can capture. Drawing an example from the CCES is quite useful, as the 60k total sample is much larger than typical publicly available surveys, and so we can check behavior under larger N sizes. Practically, fitting this with rstanarm allows us to switch easily from a great MCMC implementation to a decent VI optimizer quickly for some early tests. Finally, the complexity and runtime of the model is a nice balance of being something that we can fit with MCMC in a not terrible amount of time for comparison’s sake, and something challenging enough that it should teach us something about VI’s ability to handle non-toy models of the world.\nFitting this4 with MCMC in rstanarm is as simple as:\n\n# Fit in stan_glmer\nfit <- stan_glmer(abortion ~ (1 | state) + (1 | eth) + (1 | educ) + male +\n                    (1 | male:eth) + (1 | educ:age) + (1 | educ:eth) +\n                    repvote + factor(region),\n  family = binomial(link = \"logit\"),\n  data = cces_df,\n  prior = normal(0, 1, autoscale = TRUE),\n  prior_covariance = decov(scale = 0.50),\n  adapt_delta = 0.99,\n  refresh = 0,\n  seed = 605)\n\nSince it isn’t relevant for the rest of my discussion here, I’ll summarize the model diagnostics here and say that this seems to be a pretty reasonable fit- no issues with divergences, and no issues with poor \\hat{r}’s. Worth quickly pointing out that we did have to tune adapt_delta a bit to get no divergences though- even before getting to fitting this with VI, a model like this requires some adjustments to fit correctly.\nWith a model like this on just a 5k sample, we can produce pretty solid state level predictions that have clearly benefited from being fit with a Bayesian multilevel model:\n\nWith a 5k sample, MRP lands much closer to the complete weighted survey than a 5k unweighted sample: neat. That’s certainly not a fully fair comparison, but it gives some intution around the promise of this approach.\nSomewhat less neat is that even a 5k sample here takes about 13 minutes to fit. How does this change as we fit on more and more of the data?\n\n\n\n\n\n\n\nSample Size\nRuntime\n\n\n\n\n5,000\n13 minutes\n\n\n10,000\n44 minutes\n\n\n60,000\n526 minutes (~8 hours!)\n\n\n\nAs the table above should illustrate, if you’re fitting a decently complex Bayesian model on even somewhat large N sizes, you’re pretty quickly going to cap out what you can reasonably fit in a acceptable amount of time. If you’re scaling N past the above example, or deepening the modeling complexity, you’ll pretty quickly feel effectively locked out of using these models in fast-paced environments.\nHopefully fitting my running example has helped for building intuition here. Even a reasonably complex Bayesian model can have some pretty desirable estimation properties. To make iterating on modelling choices faster, to scale our N or model complexity higher, or just to use a model like this day to day when time matters, we’d really like to scale these fitting times back. Can Variational Inference help?"
  },
  {
    "objectID": "posts/Variational MRP Pt1/variational_mrp_pt1.html#the-elbo",
    "href": "posts/Variational MRP Pt1/variational_mrp_pt1.html#the-elbo",
    "title": "Variational Inference for MRP with Reliable Posterior Distributions",
    "section": "The ELBO",
    "text": "The ELBO\nIf you haven’t seen it yet, this quick substitution should clarify a potential issue with VI as I’ve described it so far:\nq^*(z) = argmin_{q(z) \\in \\mathscr{Q}}(q(z)||\\frac{p(z,x)}{\\bf p(x)}) = \\mathbb{E}[logq(z)] - \\mathbb{E}[logp(z,x)] + {\\bf logp(x)} Without some new trick, all I’ve said so far is to approximate a thing I can’t analytically calculate (the posterior, specially the issue evidence piece of it), I’m going to calculate the distance between my approximation and… the thing I said has a component can’t calculate?\nFortunately, a clever solution exists here that makes this strategy possible. Instead of trying to minimize the above KL divergence, we can optimize the alternative objective:\n\\mathbb{E}[logp(z,x)] - \\mathbb{E}[logq(z)]\nThis is just the negative of the first two terms above, leaving aside the logp(x). Why can we treat maximizing this as minimizing the KL divergence? The logp(x) term is just a constant (with respect to q), so regardless of how we vary q, this will still be a valid alternative objective. We call this the Evidence Lower Bound (ELBO)6.\nIf it’s helpful for intuition, play around with this great interactive ELBO optimizer by Felix Köhler:\n\n\n\n\n\n\n\n\n\n\n\nLink to demonstration here; check out Felix’s Youtube explanation of the ELBO also!\n\n\n\n\n\nBy twiddling the knobs on \\mu and \\sigma for our approximating normal, we can get our surrogate distribution pretty close to the True Posterior (which we know for purposes of demonstration, so we can calculate the true KL, not just it’s ELBO component). No matter how we twiddle though, the evidence remains constant.\nFor further intuition- notice that we can only do this trick in one direction. The KL divergence isn’t symmetrical, and if we wanted to calculate the “reverse” KL, we couldn’t use this strategy as logq(x) would not be a constant. Even if we thought that optimizing other direction of KL might have desirable properties like emphasizing mass-seeking over mode-seeking behavior, that simply isn’t an option."
  },
  {
    "objectID": "posts/Variational MRP Pt2/Variational_MRP_pt2.html",
    "href": "posts/Variational MRP Pt2/Variational_MRP_pt2.html",
    "title": "Variational Inference for MRP with Reliable Posterior Distributions",
    "section": "",
    "text": "This is the second post in my series on using Variational Inference to speed up relatively complex Bayesian models like Multilevel Regression and Poststratification without the approximation being of disastrously poor quality.\nIn the last post, I laid out why such reformulating the Bayesian inference problem as optimization might be desirable, but previewed why this might be quite hard to find high quality approximations amenable to optimization. I then introduced our running example (predicting national/sub-national opinion on an abortion question from the CCES using MRP), and gave an initial introduction to a version of Variational Inference where we maximize the Evidence Lower Bound (ELBO) as an objective, and do so using a mean-field Gaussian approximation. We saw that with 60k examples, this took about 8 hours to fit with MCMC, but 144 seconds (!) with VI.\nIn this post, we’ll explore the shortcomings of this initial approximation, and take a first pass at trying to better with a more complex (full rank) variational approximation. The goal is to get a better feel for what failing models could look like, at least in this relatively simple case.\nThe rough plan for the series is as follows:"
  },
  {
    "objectID": "posts/Variational MRP Pt2/Variational_MRP_pt2.html#lowering-the-tolerance",
    "href": "posts/Variational MRP Pt2/Variational_MRP_pt2.html#lowering-the-tolerance",
    "title": "Variational Inference for MRP with Reliable Posterior Distributions",
    "section": "Lowering the tolerance",
    "text": "Lowering the tolerance\nSo we managed to structure our Bayesian inference problem as an optimization problem. Can’t we just optimize better? Maybe with more training the result will be less bad?\nthe tol_rel_obj parameter control’s the convergence tolerance on the relative norm of the objective. In other words, it controls what (change in the) Evidence Lower Bound value we consider accurate enough to stop at. The default is 0.01, which feels a bit opaque, but let’s try setting it way down to 1e-8 (1Mx lower). Then we can plot it alongside the MCMC estimates and original MF-VI attempt.\n\ntic()\nfit_60k_1e8 <- stan_glmer(abortion ~ (1 | state) + (1 | eth) + (1 | educ) +\n                                      male + (1 | male:eth) + (1 | educ:age) +\n                                      (1 | educ:eth) + repvote + factor(region),\n  family = binomial(link = \"logit\"),\n  data = cces_all_df,\n  prior = normal(0, 1, autoscale = TRUE),\n  prior_covariance = decov(scale = 0.50),\n  adapt_delta = 0.99,\n  # Printing the ELBO every 1k draws\n  refresh = 1000,\n  tol_rel_obj = 1e-8,\n  algorithm = \"meanfield\",\n  seed = 605)\n\nChain 1: ------------------------------------------------------------\nChain 1: EXPERIMENTAL ALGORITHM:\nChain 1:   This procedure has not been thoroughly tested and may be unstable\nChain 1:   or buggy. The interface is subject to change.\nChain 1: ------------------------------------------------------------\nChain 1: \nChain 1: \nChain 1: \nChain 1: Gradient evaluation took 0.032 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 320 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Begin eta adaptation.\nChain 1: Iteration:   1 / 250 [  0%]  (Adaptation)\nChain 1: Iteration:  50 / 250 [ 20%]  (Adaptation)\nChain 1: Iteration: 100 / 250 [ 40%]  (Adaptation)\nChain 1: Iteration: 150 / 250 [ 60%]  (Adaptation)\nChain 1: Iteration: 200 / 250 [ 80%]  (Adaptation)\nChain 1: Success! Found best value [eta = 1] earlier than expected.\nChain 1: \nChain 1: Begin stochastic gradient ascent.\nChain 1:   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes \nChain 1:    100       -40291.889             1.000            1.000\nChain 1:    200       -39947.669             0.504            1.000\nChain 1:    300       -39802.182             0.337            0.009\nChain 1:    400       -39776.283             0.253            0.009\nChain 1:    500       -39733.863             0.203            0.004\nChain 1:    600       -39733.198             0.169            0.004\nChain 1:    700       -39728.255             0.145            0.001\nChain 1:    800       -39784.557             0.127            0.001\nChain 1:    900       -39724.366             0.113            0.001\nChain 1:   1000       -39732.042             0.102            0.001\nChain 1:   1100       -39731.525             0.002            0.001\nChain 1:   1200       -39732.049             0.001            0.001\nChain 1:   1300       -39728.119             0.001            0.000\nChain 1:   1400       -39740.928             0.000            0.000\nChain 1:   1500       -39726.114             0.000            0.000\nChain 1:   1600       -39734.740             0.000            0.000\nChain 1:   1700       -39734.129             0.000            0.000\nChain 1:   1800       -39740.719             0.000            0.000\nChain 1:   1900       -39743.591             0.000            0.000\nChain 1:   2000       -39737.155             0.000            0.000\nChain 1:   2100       -39720.432             0.000            0.000\nChain 1:   2200       -39738.138             0.000            0.000\nChain 1:   2300       -39731.045             0.000            0.000\nChain 1:   2400       -39716.393             0.000            0.000\nChain 1:   2500       -39729.189             0.000            0.000\nChain 1:   2600       -39722.239             0.000            0.000\nChain 1:   2700       -39719.508             0.000            0.000\nChain 1:   2800       -39718.709             0.000            0.000\nChain 1:   2900       -39735.110             0.000            0.000\nChain 1:   3000       -39725.900             0.000            0.000\nChain 1:   3100       -39726.123             0.000            0.000\nChain 1:   3200       -39718.736             0.000            0.000\nChain 1:   3300       -39718.141             0.000            0.000\nChain 1:   3400       -39717.147             0.000            0.000\nChain 1:   3500       -39725.738             0.000            0.000\nChain 1:   3600       -39732.190             0.000            0.000\nChain 1:   3700       -39723.666             0.000            0.000\nChain 1:   3800       -39725.470             0.000            0.000\nChain 1:   3900       -39741.504             0.000            0.000\nChain 1:   4000       -39722.951             0.000            0.000\nChain 1:   4100       -39721.852             0.000            0.000\nChain 1:   4200       -39717.894             0.000            0.000\nChain 1:   4300       -39717.474             0.000            0.000\nChain 1:   4400       -39716.244             0.000            0.000\nChain 1:   4500       -39727.542             0.000            0.000\nChain 1:   4600       -39716.670             0.000            0.000\nChain 1:   4700       -39723.714             0.000            0.000\nChain 1:   4800       -39727.123             0.000            0.000\nChain 1:   4900       -39722.517             0.000            0.000\nChain 1:   5000       -39722.485             0.000            0.000\nChain 1:   5100       -39719.107             0.000            0.000\nChain 1:   5200       -39722.873             0.000            0.000\nChain 1:   5300       -39720.153             0.000            0.000\nChain 1:   5400       -39718.807             0.000            0.000\nChain 1:   5500       -39719.687             0.000            0.000\nChain 1:   5600       -39730.850             0.000            0.000\nChain 1:   5700       -39719.315             0.000            0.000\nChain 1:   5800       -39717.985             0.000            0.000\nChain 1:   5900       -39715.943             0.000            0.000\nChain 1:   6000       -39721.574             0.000            0.000\nChain 1:   6100       -39716.072             0.000            0.000\nChain 1:   6200       -39715.947             0.000            0.000\nChain 1:   6300       -39716.325             0.000            0.000\nChain 1:   6400       -39716.206             0.000            0.000\nChain 1:   6500       -39720.508             0.000            0.000\nChain 1:   6600       -39717.566             0.000            0.000\nChain 1:   6700       -39718.903             0.000            0.000\nChain 1:   6800       -39716.766             0.000            0.000\nChain 1:   6900       -39724.482             0.000            0.000\nChain 1:   7000       -39717.376             0.000            0.000\nChain 1:   7100       -39721.566             0.000            0.000\nChain 1:   7200       -39725.641             0.000            0.000\nChain 1:   7300       -39717.909             0.000            0.000\nChain 1:   7400       -39720.096             0.000            0.000\nChain 1:   7500       -39716.243             0.000            0.000\nChain 1:   7600       -39738.451             0.000            0.000\nChain 1:   7700       -39715.841             0.000            0.000\nChain 1:   7800       -39716.561             0.000            0.000\nChain 1:   7900       -39716.865             0.000            0.000\nChain 1:   8000       -39721.972             0.000            0.000\nChain 1:   8100       -39723.864             0.000            0.000\nChain 1:   8200       -39716.157             0.000            0.000\nChain 1:   8300       -39720.235             0.000            0.000\nChain 1:   8400       -39718.693             0.000            0.000\nChain 1:   8500       -39727.325             0.000            0.000\nChain 1:   8600       -39716.809             0.000            0.000\nChain 1:   8700       -39716.760             0.000            0.000\nChain 1:   8800       -39721.577             0.000            0.000\nChain 1:   8900       -39716.910             0.000            0.000\nChain 1:   9000       -39721.631             0.000            0.000\nChain 1:   9100       -39721.102             0.000            0.000\nChain 1:   9200       -39718.303             0.000            0.000\nChain 1:   9300       -39715.759             0.000            0.000\nChain 1:   9400       -39719.769             0.000            0.000\nChain 1:   9500       -39719.046             0.000            0.000\nChain 1:   9600       -39720.854             0.000            0.000\nChain 1:   9700       -39717.968             0.000            0.000\nChain 1:   9800       -39721.396             0.000            0.000\nChain 1:   9900       -39728.139             0.000            0.000\nChain 1:   10000       -39715.367             0.000            0.000\nChain 1: Informational Message: The maximum number of iterations is reached! The algorithm may not have converged.\nChain 1: This variational approximation is not guaranteed to be meaningful.\nChain 1: \nChain 1: Drawing a sample of size 1000 from the approximate posterior... \nChain 1: COMPLETED.\n\n\nWarning: Pareto k diagnostic value is 2.05. Resampling is disabled. Decreasing\ntol_rel_obj may help if variational algorithm has terminated prematurely.\nOtherwise consider using sampling instead.\n\n\nSetting 'QR' to TRUE can often be helpful when using one of the variational inference algorithms. See the documentation for the 'QR' argument.\n\ntoc()\n\n298.73 sec elapsed\n\nlower_tol_draws <- poststrat_df_60k %>% add_epred_draws(fit_60k_1e8, ndraws = 1000)\n\nmfvi_lower_tol_points <- lower_tol_draws %>% \n                        group_by(state,.draw) %>%\n                        summarize(postrat_draw = sum(.epred*(n/sum(n)))) %>%\n                        mutate(model = \"MF-VI 1e-8\")\n\ncombined_points_w_lower_tol <- combined_points %>%\n                      bind_rows(mfvi_lower_tol_points) %>%\n                      ungroup()\n\ncombined_points_w_lower_tol %>%\n  mutate(ordered_state = fct_reorder(combined_points_w_lower_tol$state,\n                                     combined_points_w_lower_tol$postrat_draw)) %>%\n  ggplot(aes(y = ordered_state,\n             x = postrat_draw,\n             color = model)) +\n     stat_dots(quantiles = 100) +\n     facet_wrap(~model) +\n     theme(legend.position=\"none\") +\n  xlab(\"Should employers be allowed to deny their employees abortion care?\") +\n  ylab(\"State\")\n\n\n\n\n… That certainly looks different, but I don’t really think I’d say it looks meaningfully better4.\nLooking at the printed out ELBO, it’s pretty clear that there was no traction after the first ~1000 samples. A variational family this simple isn’t going to get much better, no matter how much time you give it."
  },
  {
    "objectID": "posts/Variational MRP Pt2/Variational_MRP_pt2.html#full-rank-approximation",
    "href": "posts/Variational MRP Pt2/Variational_MRP_pt2.html#full-rank-approximation",
    "title": "Variational Inference for MRP with Reliable Posterior Distributions",
    "section": "Full-Rank Approximation",
    "text": "Full-Rank Approximation\nSo if extend training time, but improvements don’t result, maybe the next option is ask whether we need something more sophisticated than a mean-field approximation. Instead of\nq(z) = \\prod_{j=1}^{m} q_j(z_j)\nlet’s now try the full-rank approximation. Gather than each z_j getting it’s own independent Gaussian, this uses a single multivariate normal distribution- so we can now (roughly) learn correlation structure, fancy.\nq(z) = \\mathcal{N}(z|\\mu,\\Sigma)\n\ntic()\nfit_60k_fullrank <- stan_glmer(abortion ~ (1 | state) + (1 | eth) + (1 | educ) +\n                                      male + (1 | male:eth) + (1 | educ:age) +\n                                      (1 | educ:eth) + repvote + factor(region),\n  family = binomial(link = \"logit\"),\n  data = cces_all_df,\n  prior = normal(0, 1, autoscale = TRUE),\n  prior_covariance = decov(scale = 0.50),\n  adapt_delta = 0.99,\n  tol_rel_obj = 1e-8,\n  # Printing the ELBO every 1k draws\n  refresh = 1000,\n  algorithm = \"fullrank\",\n  QR = TRUE,\n  seed = 605)\n\nChain 1: ------------------------------------------------------------\nChain 1: EXPERIMENTAL ALGORITHM:\nChain 1:   This procedure has not been thoroughly tested and may be unstable\nChain 1:   or buggy. The interface is subject to change.\nChain 1: ------------------------------------------------------------\nChain 1: \nChain 1: \nChain 1: \nChain 1: Gradient evaluation took 0.025 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 250 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Begin eta adaptation.\nChain 1: Iteration:   1 / 250 [  0%]  (Adaptation)\nChain 1: Iteration:  50 / 250 [ 20%]  (Adaptation)\nChain 1: Iteration: 100 / 250 [ 40%]  (Adaptation)\nChain 1: Iteration: 150 / 250 [ 60%]  (Adaptation)\nChain 1: Iteration: 200 / 250 [ 80%]  (Adaptation)\nChain 1: Iteration: 250 / 250 [100%]  (Adaptation)\nChain 1: Success! Found best value [eta = 0.1].\nChain 1: \nChain 1: Begin stochastic gradient ascent.\nChain 1:   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes \nChain 1:    100      -248586.032             1.000            1.000\nChain 1:    200      -180460.369             0.689            1.000\nChain 1:    300      -121675.221             0.620            0.483\nChain 1:    400       -87431.017             0.563            0.483\nChain 1:    500      -120999.829             0.506            0.392\nChain 1:    600       -96768.296             0.463            0.392\nChain 1:    700       -93851.607             0.402            0.378\nChain 1:    800       -92494.273             0.353            0.378\nChain 1:    900       -74378.556             0.341            0.277\nChain 1:   1000       -77681.560             0.311            0.277\nChain 1:   1100       -77465.866             0.211            0.250\nChain 1:   1200       -68692.287             0.186            0.244\nChain 1:   1300       -75140.633             0.147            0.128\nChain 1:   1400       -49430.772             0.160            0.128\nChain 1:   1500       -59011.994             0.148            0.128\nChain 1:   1600       -57033.572             0.127            0.086\nChain 1:   1700       -56133.855             0.125            0.086\nChain 1:   1800       -46605.149             0.144            0.128\nChain 1:   1900       -47895.964             0.122            0.086\nChain 1:   2000       -44745.890             0.125            0.086\nChain 1:   2100       -43472.467             0.128            0.086\nChain 1:   2200       -43454.384             0.115            0.070\nChain 1:   2300       -41781.249             0.110            0.040\nChain 1:   2400       -42045.221             0.059            0.035\nChain 1:   2500       -41381.652             0.044            0.029\nChain 1:   2600       -40754.440             0.043            0.027\nChain 1:   2700       -41108.136             0.042            0.027\nChain 1:   2800       -40450.439             0.023            0.016\nChain 1:   2900       -40423.015             0.020            0.016\nChain 1:   3000       -40375.121             0.013            0.015\nChain 1:   3100       -40227.022             0.011            0.009\nChain 1:   3200       -40302.411             0.011            0.009\nChain 1:   3300       -40352.339             0.007            0.006\nChain 1:   3400       -40174.196             0.007            0.004\nChain 1:   3500       -40089.973             0.006            0.004\nChain 1:   3600       -40143.009             0.004            0.002\nChain 1:   3700       -40123.486             0.003            0.002\nChain 1:   3800       -40044.004             0.002            0.002\nChain 1:   3900       -39955.515             0.002            0.002\nChain 1:   4000       -40003.851             0.002            0.002\nChain 1:   4100       -39948.544             0.002            0.002\nChain 1:   4200       -40028.027             0.002            0.002\nChain 1:   4300       -39907.006             0.002            0.002\nChain 1:   4400       -39868.266             0.002            0.002\nChain 1:   4500       -39938.386             0.002            0.002\nChain 1:   4600       -39837.339             0.002            0.002\nChain 1:   4700       -39852.349             0.002            0.002\nChain 1:   4800       -39823.670             0.002            0.002\nChain 1:   4900       -39809.797             0.001            0.001\nChain 1:   5000       -39807.261             0.001            0.001\nChain 1:   5100       -39806.402             0.001            0.001\nChain 1:   5200       -39818.805             0.001            0.001\nChain 1:   5300       -39797.428             0.001            0.001\nChain 1:   5400       -39790.469             0.001            0.000\nChain 1:   5500       -39785.797             0.001            0.000\nChain 1:   5600       -39779.121             0.000            0.000\nChain 1:   5700       -39780.314             0.000            0.000\nChain 1:   5800       -39771.363             0.000            0.000\nChain 1:   5900       -39770.673             0.000            0.000\nChain 1:   6000       -39764.096             0.000            0.000\nChain 1:   6100       -39764.173             0.000            0.000\nChain 1:   6200       -39765.651             0.000            0.000\nChain 1:   6300       -39756.809             0.000            0.000\nChain 1:   6400       -39753.724             0.000            0.000\nChain 1:   6500       -39754.753             0.000            0.000\nChain 1:   6600       -39750.392             0.000            0.000\nChain 1:   6700       -39753.067             0.000            0.000\nChain 1:   6800       -39750.341             0.000            0.000\nChain 1:   6900       -39745.696             0.000            0.000\nChain 1:   7000       -39743.521             0.000            0.000\nChain 1:   7100       -39739.157             0.000            0.000\nChain 1:   7200       -39736.689             0.000            0.000\nChain 1:   7300       -39743.472             0.000            0.000\nChain 1:   7400       -39738.431             0.000            0.000\nChain 1:   7500       -39740.789             0.000            0.000\nChain 1:   7600       -39735.842             0.000            0.000\nChain 1:   7700       -39733.493             0.000            0.000\nChain 1:   7800       -39735.015             0.000            0.000\nChain 1:   7900       -39736.429             0.000            0.000\nChain 1:   8000       -39733.548             0.000            0.000\nChain 1:   8100       -39732.722             0.000            0.000\nChain 1:   8200       -39734.720             0.000            0.000\nChain 1:   8300       -39732.932             0.000            0.000\nChain 1:   8400       -39727.658             0.000            0.000\nChain 1:   8500       -39734.522             0.000            0.000\nChain 1:   8600       -39728.602             0.000            0.000\nChain 1:   8700       -39724.690             0.000            0.000\nChain 1:   8800       -39725.374             0.000            0.000\nChain 1:   8900       -39731.450             0.000            0.000\nChain 1:   9000       -39725.866             0.000            0.000\nChain 1:   9100       -39728.639             0.000            0.000\nChain 1:   9200       -39730.156             0.000            0.000\nChain 1:   9300       -39729.036             0.000            0.000\nChain 1:   9400       -39725.536             0.000            0.000\nChain 1:   9500       -39727.031             0.000            0.000\nChain 1:   9600       -39725.389             0.000            0.000\nChain 1:   9700       -39727.947             0.000            0.000\nChain 1:   9800       -39723.932             0.000            0.000\nChain 1:   9900       -39723.173             0.000            0.000\nChain 1:   10000       -39723.944             0.000            0.000\nChain 1: Informational Message: The maximum number of iterations is reached! The algorithm may not have converged.\nChain 1: This variational approximation is not guaranteed to be meaningful.\nChain 1: \nChain 1: Drawing a sample of size 1000 from the approximate posterior... \nChain 1: COMPLETED.\n\n\nWarning: Pareto k diagnostic value is 2.95. Resampling is disabled. Decreasing\ntol_rel_obj may help if variational algorithm has terminated prematurely.\nOtherwise consider using sampling instead.\n\ntoc()\n\n350.16 sec elapsed\n\nfull_rank_draws <- poststrat_df_60k %>% add_epred_draws(fit_60k_fullrank,\n                                                        ndraws = 1000)\n\nfrvi_points <- full_rank_draws %>% \n                        group_by(state,.draw) %>%\n                        summarize(postrat_draw = sum(.epred*(n/sum(n)))) %>%\n                        mutate(model = \"FR-VI\")\n\ncombined_points_w_frvi <- combined_points_w_lower_tol %>%\n                      bind_rows(frvi_points) %>%\n                      ungroup()\n\ncombined_points_w_frvi %>%\n  mutate(ordered_state = fct_reorder(combined_points_w_frvi$state,\n                                     combined_points_w_frvi$postrat_draw)) %>%\n  ggplot(aes(y = ordered_state,\n             x = postrat_draw,\n             color = model)) +\n     stat_dots(quantiles = 100) +\n     facet_wrap(~model) +\n     theme(legend.position=\"none\") +\n  xlab(\"Should employers be allowed to deny their employees abortion care?\") +\n  ylab(\"State\")\n\n\n\n\nThe first thing to note here is that unlike the mean-field approximation, fitting this model required some tinkering to get it to fit. I ended up needing to set QR = TRUE (ie, use a QR decomposition) to get this to fit at all (unless I set the initialization to 0, at which point the posterior collapsed to nearly a single point).\nUnfortunately, this version has a similar spiky posterior distribution. In terms of uncertainty, it’s clearly worse than the mean-field implementation. The ELBO starts from higher, spends some time actually improving, but also quickly reaches a plateau. It doesn’t seem like this is a way out either."
  }
]