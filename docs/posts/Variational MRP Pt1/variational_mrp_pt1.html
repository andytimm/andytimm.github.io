<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Andy Timm">
<meta name="dcterms.date" content="2022-10-10">

<title>Variational Inference for MRP with Reliable Posterior Distributions – Andy Timm</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-0a95de2c3be981c2e03029825b16c585.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-20d62a5fbd1c99d0ea726841186458c1.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Variational Inference for MRP with Reliable Posterior Distributions – Andy Timm">
<meta property="og:description" content="Introductions- things to do, places to be">
<meta property="og:image" content="https://andytimm.github.io/posts/Variational MRP Pt1/elboplot.png">
<meta property="og:site_name" content="Andy Timm">
<meta property="og:image:height" content="514">
<meta property="og:image:width" content="1726">
<meta name="twitter:title" content="Variational Inference for MRP with Reliable Posterior Distributions – Andy Timm">
<meta name="twitter:description" content="Introductions- things to do, places to be">
<meta name="twitter:image" content="https://andytimm.github.io/posts/Variational MRP Pt1/elboplot.png">
<meta name="twitter:creator" content="@andy_timm">
<meta name="twitter:site" content="@andy_timm">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image-height" content="514">
<meta name="twitter:image-width" content="1726">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Andy Timm</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../software.html"> 
<span class="menu-text">Software</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html"> 
<span class="menu-text">Rarely Updated Blog</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Variational Inference for MRP with Reliable Posterior Distributions</h1>
            <p class="subtitle lead">Introductions- things to do, places to be</p>
                                <div class="quarto-categories">
                <div class="quarto-category">MRP</div>
                <div class="quarto-category">BART</div>
                <div class="quarto-category">Variational Inference</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p><a href="https://andytimm.github.io">Andy Timm</a> </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">October 10, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#motivation-for-series" id="toc-motivation-for-series" class="nav-link active" data-scroll-target="#motivation-for-series">Motivation for series</a></li>
  <li><a href="#spherical-cow-sadness" id="toc-spherical-cow-sadness" class="nav-link" data-scroll-target="#spherical-cow-sadness">Spherical Cow Sadness</a></li>
  <li><a href="#introducing-mrp-and-our-running-example" id="toc-introducing-mrp-and-our-running-example" class="nav-link" data-scroll-target="#introducing-mrp-and-our-running-example">Introducing MRP and our running example</a>
  <ul>
  <li><a href="#introducing-mrp" id="toc-introducing-mrp" class="nav-link" data-scroll-target="#introducing-mrp">Introducing MRP</a></li>
  <li><a href="#introducing-the-running-example" id="toc-introducing-the-running-example" class="nav-link" data-scroll-target="#introducing-the-running-example">Introducing the Running Example</a></li>
  </ul></li>
  <li><a href="#introducing-variational-inference" id="toc-introducing-variational-inference" class="nav-link" data-scroll-target="#introducing-variational-inference">Introducing Variational Inference</a>
  <ul>
  <li><a href="#the-elbo" id="toc-the-elbo" class="nav-link" data-scroll-target="#the-elbo">The ELBO</a></li>
  </ul></li>
  <li><a href="#a-first-try-at-vi-on-this-dataset" id="toc-a-first-try-at-vi-on-this-dataset" class="nav-link" data-scroll-target="#a-first-try-at-vi-on-this-dataset">A first try at VI on this dataset</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>This post introduces a series I intend to write, exploring using <a href="https://en.wikipedia.org/wiki/Variational_Bayesian_methods">Variational Inference</a> to massively speed up running complex survey estimation models like variants of <a href="https://en.wikipedia.org/wiki/Multilevel_regression_with_poststratification">Multilevel Regression and Poststratification</a> while aiming to keep approximation error from completely ruining the model.</p>
<p>The rough plan for the series is as follows:</p>
<ol type="1">
<li><strong>(This post)</strong> Introducing the Problem- Why is VI useful, why VI can produce spherical cows</li>
<li>How far does iteration on classic VI algorithms like mean-field and full-rank get us?</li>
<li>Some theory on why posterior approximation with VI can be so poor</li>
<li>Seeing if some more sophisticated techniques like normalizing flows help</li>
</ol>
<section id="motivation-for-series" class="level1">
<h1>Motivation for series</h1>
<p>I learn well by explaining things to others, and I’ve been particularly excited to learn about variational inference and ways to improve it over the past few months. There are lots of Bayesian models I would like to fit, especially in my political work, that I would categorize as being incredibly useful, but on the edge of practically acceptable run times. For example, the somewhat but not particularly complex model I’ll use as a running example for the series <strong>takes ~8 hours to fit on 60k observations</strong>.</p>
<p>Having a model run overnight or for a full work day can be fine sometimes, but what if there is a more urgent need for the results? What if we need to iterate to find the “right” model? What if the predictions from this model need to feed into a later one? How constrained do we feel about adding just a little bit more complexity to the model, or increasing our N size just a bit more?</p>
<p>If we can get VI to fit well, we can make complex Bayesian models a lot more practical to use in a wider variety of scenarios, and maybe even extend the complexity of what we can build given time and resource constraints.</p>
</section>
<section id="spherical-cow-sadness" class="level1">
<h1>Spherical Cow Sadness</h1>
<section id="ive-got-that" class="level5">
<h5 class="anchored" data-anchor-id="ive-got-that">I’ve got that…</h5>
<div class="quarto-layout-panel" data-layout="[25,-2,10]">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 67.6%;justify-content: center;">
<p><img src="rstanarm_disclaimer.png" class="img-fluid"></p>
</div>
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 5.4%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 27.0%;justify-content: center;">
<p><img src="blei_vi_spherical.png" class="img-fluid"></p>
</div>
</div>
</div>
<p>If VI can make Bayesian inference much faster, what’s the catch? The above two images encapsulate the problem pretty well. First, as the left screenshot from <a href="https://mc-stan.org/rstanarm/reference/rstanarm-package.html#estimation-algorithms">rstanarm’s documentation</a> shows, variational inference requires a (bold text warning requiring) set of approximating distribution choices in order to be tractable to optimize. On the right, in their survey paper on VI, <a href="https://arxiv.org/pdf/1601.00670.pdf">Blei et al.&nbsp;(2018)</a> are showing one of the potential posterior distorting consequences of our choice to approximate.</p>
<p>So stepping back for a second, we’ve taken a problem for which there’s usually no closed form solution (Bayesian inference), where even the best approximation algorithm we can usually use (MCMC) isn’t always enough for valid inference without very careful validation and tinkering. Then we decided our approximation could do with being more approximate.</p>
<p>That was perhaps an overly bleak description, but it should give some intuition why this is a hard problem. We want to choose some method of approximating our posterior such that it is amenable to optimization-based solving instead of requiring sampling, but not trade away our ability to correctly understand the full complexity of the posterior distribution<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
</section>
</section>
<section id="introducing-mrp-and-our-running-example" class="level1">
<h1>Introducing MRP and our running example</h1>
<section id="introducing-mrp" class="level2">
<h2 class="anchored" data-anchor-id="introducing-mrp">Introducing MRP</h2>
<p>While I’m mostly focused on the way we choose to actually fit a given model with this series, here’s a super quick review of the intuition in building a MRP model. If you want a more complete introduction, Kastellec’s <a href="https://scholar.princeton.edu/jkastellec/publications">MRP Primer</a> is a great starting point, as are the case studies I link a bit later.</p>
<p>MRP casts estimation of a population quantity of interest <span class="math inline">\theta</span> as a prediction problem. That is, instead of the more traditional approach of building <a href="https://www.pewresearch.org/methods/2018/01/26/how-different-weighting-methods-work/#raking">simple raked weights</a> and using weighted estimators, MRP leans more heavily on modeling and then poststratification to make the estimates representative.</p>
<p>To sketch out the steps-</p>
<ol type="1">
<li>Either gather or run a survey or collection of surveys that collect both information on the outcome of interest, <span class="math inline">y</span>, and a set of demographic and geographic predictors, <span class="math inline">\left(X_{1}, X_{2}, X_{3}, \ldots, X_{m}\right)</span>.</li>
<li>Build a poststratification table, with population counts or estimated population counts <span class="math inline">N_{j}</span> for each possible combination of the features gathered above. Each possible combination <span class="math inline">j</span> is called a cell, one of <span class="math inline">J</span> possible cells. For example, if we poststratified only on state, there would be <span class="math inline">J=51</span> (with DC) total cells; in practice, <span class="math inline">J</span> is often several thousand.</li>
<li>Build a model, usually a Bayesian multilevel regression, to predict <span class="math inline">y</span> using the demographic characteristic from the survey or set of surveys, estimating model parameters along the way.</li>
<li>Estimate <span class="math inline">y</span> for each cell in the poststratification table, using the model built on the sample.</li>
<li>Aggregate the cells to the population of interest, weighting by the <span class="math inline">N_{j}</span>’s to obtain population level estimates: <span class="math display">\theta_{\mathrm{POP}}=\frac{\sum_{j \in J} N_{j} \theta_{j}}{\sum_{j \in J} N_{J}}</span></li>
</ol>
<p>Why would we want to do this over building more typical survey weights? To the extent your new model has desirable properties like the ability to incorporate priors, can partially pool to manage rare subpopulations where you don’t have a lot of sample, and so on, you can get the benefits of that more efficient model through MRP. Raking in its simplest form is really just a linear model; we have plenty of methods that can do better. Outside of bayesian multilevel models which are the most common, there’s an increasing literature on using a wide variety of machine learning algorithms like BART<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> to do the estimation stage; Andrew Gelman calls this <a href="https://statmodeling.stat.columbia.edu/2018/05/19/regularized-prediction-poststratification-generalization-mister-p/">RRP</a>.</p>
</section>
<section id="introducing-the-running-example" class="level2">
<h2 class="anchored" data-anchor-id="introducing-the-running-example">Introducing the Running Example</h2>
<p>Rather than reinvent the wheel, I’ll follow the lead of the excellent <a href="https://bookdown.org/jl5522/MRP-case-studies/">Multilevel Regression and Poststratification Case Studies</a> by Lopez-Martin, Philips, and Gelman, and model survey binary responses from the <a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/ZSBZ7K">2018 CCES</a> for the following question:</p>
<blockquote class="blockquote">
<p>Allow employers to decline coverage of abortions in insurance plans (Support / Oppose)</p>
</blockquote>
<p>From the CCES, we get information on each participant’s state, age, gender, ethnicity, and education level. Supplementing this individual level data, we also include region flags for each state, and Republican vote share in the 2016 election- these state level predictors have been shown to be critical for getting strong MRP estimates by <a href="http://www.columbia.edu/~jhp2121/publications/HowShouldWeEstimateOpinion.pdf">Lax and Philips (2009)</a> and others. and If you’d like deeper detail on the dataset itself, I’d refer you to <a href="https://bookdown.org/jl5522/MRP-case-studies/introduction-to-mister-p.html#ref-2018CCES">this part</a> MRP case study.</p>
<p>Using these, we setup the model for <span class="math inline">Pr(y_i = 1)</span> the probability of supporting allowing employers to decline coverage of abortions in insurance plans as:</p>
<p><span class="math display">
\begin{aligned}
Pr(y_i = 1) =&amp; logit^{-1}(
\gamma^0
+ \alpha_{\rm s[i]}^{\rm state}
+ \alpha_{\rm a[i]}^{\rm age}
+ \alpha_{\rm r[i]}^{\rm eth}
+ \alpha_{\rm e[i]}^{\rm educ}
+ \beta^{\rm male} \cdot {\rm Male}_{\rm i} \\
&amp;+ \alpha_{\rm g[i], r[i]}^{\rm male.eth}
+ \alpha_{\rm e[i], a[i]}^{\rm educ.age}
+ \alpha_{\rm e[i], r[i]}^{\rm educ.eth}
+ \gamma^{\rm south} \cdot {\rm South}_{\rm s} \\
&amp;+ \gamma^{\rm northcentral} \cdot {\rm NorthCentral}_{\rm s}
+ \gamma^{\rm west} \cdot {\rm West}_{\rm s}
+ \gamma^{\rm repvote} \cdot {\rm RepVote}_{\rm s})
\end{aligned}
</span></p>
<p>Where we incorporate pretty much all of our predictors as varying intercepts to allow for pooling across demographic and geographic characteristics:</p>
<ul>
<li><p><span class="math inline">\alpha_{\rm a}^{\rm age}</span>: The effect of subject <span class="math inline">i</span>’s age on the probability of supporting the statement.</p></li>
<li><p><span class="math inline">\alpha_{\rm r}^{\rm eth}</span>: The effect of subject <span class="math inline">i</span>’s ethnicity on the probability of supporting the statement.</p></li>
<li><p><span class="math inline">\alpha_{\rm e}^{\rm educ}</span>: The effect of subject <span class="math inline">i</span>’s education on the probability of supporting the statement.</p></li>
<li><p><span class="math inline">\alpha_{\rm s}^{\rm state}</span>: The effect of subject <span class="math inline">i</span>’s state on the probability of supporting the statement.</p></li>
<li><p><span class="math inline">\beta^{\rm male}</span>: The average effect of being male on the probability of supporting abortion. Note that it doesn’t really make much sense to model a two category<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> factor as a varying intercept.</p></li>
<li><p><span class="math inline">\alpha_{\rm e,r}^{\rm male.eth}</span>, <span class="math inline">\alpha_{\rm e,r}^{\rm educ.age}</span>, <span class="math inline">\alpha_{\rm e,r}^{\rm educ.eth}</span>: Are several reasonable guesses at important interactions for this question. We could add many more two way, or even some three way interactions here, but this is enough for my testing here.</p></li>
<li><p><span class="math inline">\gamma^{\rm south}, \gamma^{\rm northcentral}, \gamma^{\rm west},\gamma^{\rm repvote}</span>: are the state level predictors which are not represented as varying intercepts. Following the case study, I use <span class="math inline">\gamma</span>’s for the state level coefficients, keeping <span class="math inline">\beta</span>’s for individual coefficients. Note that Northeast is the base region of the region factor here, so it doesn’t get it’s own coefficient.</p></li>
</ul>
<p>Stepping back for a second, let’s describe the complexity of this model in more general terms. This certainly isn’t state of the art for MRP, and you could definitely add in things like a lot more interactions, some varying slopes, non-univariate prior and/or structured priors, or other elements to make this a more interesting model. That said, this is already clearly enough of a model to improve on simple raking in many cases, and it produces a nuanced enough posterior that we can feasibly imagine a bad approximation going all spherical cow shaped on us.</p>
<p>Why this dataset and this model for this series? The question we model itself isn’t super important- as long as we can expect some significant regional and demographic variation in the outcome we’ll be able to explore if VI smoothes away some posterior complexity that MCMC can capture. Drawing an example from the CCES is quite useful, as the 60k total sample is much larger than typical publicly available surveys, and so we can check behavior under larger N sizes. Practically, fitting this with <code>rstanarm</code> allows us to switch easily from a great MCMC implementation to a decent VI optimizer quickly for some early tests. Finally, the complexity and runtime of the model is a nice balance of being something that we can fit with MCMC in a not terrible amount of time for comparison’s sake, and something challenging enough that it should teach us something about VI’s ability to handle non-toy models of the world.</p>
<p>Fitting this<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> with MCMC in <code>rstanarm</code> is as simple as:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit in stan_glmer</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">stan_glmer</span>(abortion <span class="sc">~</span> (<span class="dv">1</span> <span class="sc">|</span> state) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> eth) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> educ) <span class="sc">+</span> male <span class="sc">+</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>                    (<span class="dv">1</span> <span class="sc">|</span> male<span class="sc">:</span>eth) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> educ<span class="sc">:</span>age) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> educ<span class="sc">:</span>eth) <span class="sc">+</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>                    repvote <span class="sc">+</span> <span class="fu">factor</span>(region),</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">"logit"</span>),</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> cces_df,</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">autoscale =</span> <span class="cn">TRUE</span>),</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior_covariance =</span> <span class="fu">decov</span>(<span class="at">scale =</span> <span class="fl">0.50</span>),</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">adapt_delta =</span> <span class="fl">0.99</span>,</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span>,</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">605</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Since it isn’t relevant for the rest of my discussion here, I’ll summarize the model diagnostics here and say that this seems to be a pretty reasonable fit- no issues with divergences, and no issues with poor <span class="math inline">\hat{r}</span>’s. Worth quickly pointing out that we did have to tune <code>adapt_delta</code> a bit to get no divergences though- even before getting to fitting this with VI, a model like this requires some adjustments to fit correctly.</p>
<p>With a model like this on just a 5k sample, we can produce pretty solid state level predictions that have clearly benefited from being fit with a Bayesian multilevel model:</p>
<p><img src="5k_sample_full_results.png" class="img-fluid"></p>
<p>With a 5k sample, MRP lands much closer to the complete weighted survey than a 5k unweighted sample: neat. That’s certainly not a fully fair comparison, but it gives some intution around the promise of this approach.</p>
<p>Somewhat less neat is that even a 5k sample here takes about 13 minutes to fit. How does this change as we fit on more and more of the data?</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 75%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Sample Size</th>
<th style="text-align: left;">Runtime</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">5,000</td>
<td style="text-align: left;">13 minutes</td>
</tr>
<tr class="even">
<td style="text-align: left;">10,000</td>
<td style="text-align: left;">44 minutes</td>
</tr>
<tr class="odd">
<td style="text-align: left;">60,000</td>
<td style="text-align: left;">526 minutes (~8 hours!)</td>
</tr>
</tbody>
</table>
<p>As the table above should illustrate, if you’re fitting a decently complex Bayesian model on even somewhat large N sizes, you’re pretty quickly going to cap out what you can reasonably fit in a acceptable amount of time. If you’re scaling N past the above example, or deepening the modeling complexity, you’ll pretty quickly feel effectively locked out of using these models in fast-paced environments.</p>
<p>Hopefully fitting my running example has helped for building intuition here. Even a reasonably complex Bayesian model can have some pretty desirable estimation properties. To make iterating on modelling choices faster, to scale our N or model complexity higher, or just to use a model like this day to day when time matters, we’d really like to scale these fitting times back. Can Variational Inference help?</p>
</section>
</section>
<section id="introducing-variational-inference" class="level1">
<h1>Introducing Variational Inference</h1>
<p>I’ve gotten relatively far in this post without clearly explaining what Variational Inference is, and why it might provide a more efficient and scalable way to fix large Bayesian models. Let’s fully flesh that out here to ground the rest of the series.</p>
<p>In the bigger picture, pretty much all of our efforts in Bayesian inference are a form of approximate inference. Almost no models we care about for real world applications have closed form solutions- conjugate prior type situations are a math problem for stats classes, not a general tool for inference.</p>
<p>Following <a href="https://arxiv.org/abs/1601.00670">Blei et al.&nbsp;(2018)</a>’s notation, let’s setup the general problem first, describe (briefly) how MCMC solves it, and then more slowly demonstrate how VI does. Let’s say we have some observations <span class="math inline">x_{1:N}</span>, and and some latent variables that define the model <span class="math inline">z_{1:M}</span>. Note for concreteness these latent variables represent our quantities of interest: key parameters and so on- we’re calling them latent in the sense that we can’t go out and directly measure a <span class="math inline">\beta</span> or <span class="math inline">\gamma</span> from the model above, we have to gather data that allows us to estimate them. We call <span class="math inline">p(z)</span> priors, and they define our model prior to contact with the data. The goal of Bayesian inference then is conditioning on our data in order to get the posterior:</p>
<p><span class="math display">p(z|x) = \frac{p(z,x)}{p(x)}</span></p>
<p>If you’re reading this post series, it’s likely you recognize that the denominator on the right here (often called the “evidence”) is the sticking point; the integral <span class="math inline">p(x) = \int{p(z,x)dz}</span> won’t have a closed form solution.</p>
<p>When we use Markov Chain Monte Carlo as we did above to estimate the model, we’re defining a Markov Chain on <span class="math inline">z</span>, whose stationary distribution if we’ve done everything right is <span class="math inline">p(z|x)</span>. There are better and worse ways to do this certainly- the development of the <a href="https://mc-stan.org/">Stan</a> language, with associated <a href="https://mc-stan.org/docs/2_19/reference-manual/hamiltonian-monte-carlo.html">Hamiltonian Monte Carlo</a> with <a href="https://arxiv.org/abs/1111.4246">NUTS</a> sampler has massively expanded what was possible to fit in recent years. However, while actively improving the speed and scalability of sampling is an active area of research (for example, by using <a href="https://mc-stan.org/cmdstanr/articles/opencl.html">GPU compute</a> where possible), some of the speed challenges just seem a bit baked into the approach. For example, the sequential nature of markov chains makes parallelization within chains seem out of reach absent some as-yet unknown clever tricks.</p>
<p>Instead of sampling, variational inference asks what we’d need to figure out to treat the Bayesian inference problem as an <strong>optimization problem</strong>, where we could bring to bear all the tools for efficient, scalable, and parallelizable optimization we have developed.</p>
<p>Let’s start with the idea of a family of approximate densities <span class="math inline">\mathscr{Q}</span> over our latent variables<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>.</p>
<p>Within that <span class="math inline">\mathscr{Q}</span>, we want to try the best <span class="math inline">q(z)</span>, call it <span class="math inline">q^*(z)</span>, that minimizes the Kullback-Leibler divergence to the true posterior:</p>
<p><span class="math display">q^*(z) = argmin_{q(z) \in \mathscr{Q}}(q(z)||p(z|x))</span></p>
<p>If we choose a good <span class="math inline">\mathscr{Q}</span>, managing the complexity so that it includes a density close to <span class="math inline">p(z|x)</span>, without becoming too slow or impossible to optimize, this approach may provide a significant speed boost.</p>
<p>To start working with this approach though, there’s one major remaining problem. Do you see it in the equation above?</p>
<section id="the-elbo" class="level2">
<h2 class="anchored" data-anchor-id="the-elbo">The ELBO</h2>
<p>If you haven’t seen it yet, this quick substitution should clarify a potential issue with VI as I’ve described it so far:</p>
<p><span class="math display">q^*(z) = argmin_{q(z) \in \mathscr{Q}}(q(z)||\frac{p(z,x)}{\bf p(x)}) = \mathbb{E}[logq(z)] - \mathbb{E}[logp(z,x)] + {\bf logp(x)}</span> Without some new trick, all I’ve said so far is to approximate a thing I can’t analytically calculate (the posterior, specially the issue evidence piece of it), I’m going to calculate the distance between my approximation and… the thing I said has a component can’t calculate?</p>
<p>Fortunately, a clever solution exists here that makes this strategy possible. Instead of trying to minimize the above KL divergence, we can optimize the alternative objective:</p>
<p><span class="math display">\mathbb{E}[logp(z,x)] - \mathbb{E}[logq(z)]</span></p>
<p>This is just the negative of the first two terms above, leaving aside the <span class="math inline">logp(x)</span>. Why can we treat maximizing this as minimizing the KL divergence? The <span class="math inline">logp(x)</span> term is just a constant (with respect to q), so regardless of how we vary q, this will still be a valid alternative objective. We call this the Evidence Lower Bound (ELBO)<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>.</p>
<p>If it’s helpful for intuition, play around with this great interactive ELBO optimizer by Felix Köhler:</p>
<div class="quarto-layout-panel" data-layout-nrow="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 100.0%;justify-content: center;">
<p><img src="elboplot.png" class="img-fluid"></p>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 100.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="elboeqs.png" class="img-fluid figure-img"></p>
<figcaption>Link to demonstration <a href="https://englishprobabilistic-machine-learningelbo-interactive--or5u7m.streamlitapp.com/">here</a>; check out Felix’s Youtube explanation of the ELBO <a href="https://www.youtube.com/watch?v=HxQ94L8n0vU">also</a>!</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>By twiddling the knobs on <span class="math inline">\mu</span> and <span class="math inline">\sigma</span> for our approximating normal, we can get our surrogate distribution pretty close to the True Posterior (which we know for purposes of demonstration, so we can calculate the true KL, not just it’s ELBO component). No matter how we twiddle though, the evidence remains constant.</p>
<p>For further intuition- notice that we can only do this trick in one direction. The KL divergence isn’t symmetrical, and if we wanted to calculate the “reverse” KL, we couldn’t use this strategy as <span class="math inline">logq(x)</span> would not be a constant. Even if we thought that optimizing other direction of KL might have desirable properties like emphasizing <a href="https://agustinus.kristia.de/techblog/2016/12/21/forward-reverse-kl/">mass-seeking over mode-seeking behavior</a>, that simply isn’t an option.</p>
</section>
</section>
<section id="a-first-try-at-vi-on-this-dataset" class="level1">
<h1>A first try at VI on this dataset</h1>
<p>Ok, so we have an objective to optimize that should actually work. What’s a good <span class="math inline">\mathscr{Q}</span>? The choice has been shown to matter a lot, but for purposes of a first swing here, let’s try one of the simpler ideas people have explored, the mean-field family. These latent variables will be assumed mutually independent<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> and each get it’s own distinct factor in the variational density. A member of this would look something like:</p>
<p><span class="math display">q(z) = \prod_{j=1}^{m} q_j(z_j)</span></p>
<p>Each latent <span class="math inline">z_j</span> get it’s own variational factor with density <span class="math inline">q_j(z_j)</span>, whose knobs we play with to maximize the ELBO. In the particular implementation below normal distributions are used, plenty of other options like t distributions are common too.</p>
<p>Probably not the best we can do, but let’s give it a roll. Since we’ve been told this will scale really well too supposedly, let’s use all 60k of the observations just to get a sense how it’ll compare to our 8+ hours in that case.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tic</span>()</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>fit_60k <span class="ot">&lt;-</span> <span class="fu">stan_glmer</span>(abortion <span class="sc">~</span> (<span class="dv">1</span> <span class="sc">|</span> state) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> eth) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> educ) <span class="sc">+</span> male <span class="sc">+</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>                    (<span class="dv">1</span> <span class="sc">|</span> male<span class="sc">:</span>eth) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> educ<span class="sc">:</span>age) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> educ<span class="sc">:</span>eth) <span class="sc">+</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>                    repvote <span class="sc">+</span> <span class="fu">factor</span>(region),</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">"logit"</span>),</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> cces_all_df,</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">autoscale =</span> <span class="cn">TRUE</span>),</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior_covariance =</span> <span class="fu">decov</span>(<span class="at">scale =</span> <span class="fl">0.50</span>),</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">adapt_delta =</span> <span class="fl">0.99</span>,</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span>,</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">algorithm =</span> <span class="st">"meanfield"</span>,</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">605</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="fu">toc</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>This finishes in a blazing <strong>144.03 seconds</strong>. Is this a good fit, or have we created a ridiculous spherical cow?</p>
<p>You’ll have to find out in the next post. Thanks for reading!</p>
<p><em>Typically, I’ll include links to code at the end of these posts, but since the only thing going on in this notebook is mentioning some runtimes of the models displayed inline at various sample sizes, I’m skipping that for now.</em></p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>If I were that type of Bayesian, this is where I’d complain that if we screw this up badly enough, we might as well be frequentists or worse, machine learning folk.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>In grad school, using BART as the estimator (also combining it with some portions of the model being estimated as multilevel models) was the focus of my <a href="https://andytimm.github.io/posts/BART%20VI/2020-03-06-BART-vi.html">masters thesis</a>. This pairs the best parts of relatively black box machine learning sensibility with the advantages of still having a truly Bayesian model. With comparatively minimal iteration you can get a pretty decent set of MRP models that will be better than many basic versions of multilevel models fit early in the MRP literature. Of course, if you’re willing to spend a bunch of time iterating on the absolute best models for a given problem, and incorporate lots of problem specific knowledge into model forms you can and should do better than <a href="https://github.com/jbisbee1/BARP">BARP</a>. Also, a lot of pretty cool things you can do like jointly model multiple question responses at the same time aren’t going to be easily to implement unless you get way in the weeds of your own BART implementation.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Insert snark about CCES folks doing a poor job at gender inclusivity despite 80+ researchers working on it here.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Again, see the MRP case studies linked above if you want see all the data prep and draw manipulation here; I’ll be leaving out most such details that aren’t relevant for comparisons to fitting this model with VI from now on.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>In grad school, I had a friend who insisted on calling this “spicy Q”. For a while we had a latex package that made <code>\spicy{}</code> equivalent to <code>\mathscr{}</code>. Apologies for the footnote for the dumb LaTeX joke, but now I’m pretty sure you won’t have a sudden moment of “what is that symbol again” discussing VI ever.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Why is this a lower bound? Notice that we could write the evidence from above equations as <span class="math inline">logp(x) = KL(q(z)||p(z|x)) + ELBO(q)</span>. Since the KL divergence is non-negative (it’s zero when distributions <span class="math inline">p</span> and <span class="math inline">q</span> are identical), the ELBO is a lower bound of the evidence.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>If this seems like it could go fully spherical cow, both literally in the sense that if we use a bunch of independent normals we make a sphere, and in the sense that this may not represent the full complexity of public opinion, you’re correct. Assuming independence here could very easily cause problems, and part of why this VI strategy is so challenging is the subset of things we can easily optimize doesn’t have the best overlap with fully realistic distributional assumptions over our latent variables.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{timm2022,
  author = {Timm, Andy},
  title = {Variational {Inference} for {MRP} with {Reliable} {Posterior}
    {Distributions}},
  date = {2022-10-10},
  url = {https://andytimm.github.io/posts/Variational MRP Pt1/variational_mrp_pt1.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-timm2022" class="csl-entry quarto-appendix-citeas" role="listitem">
Timm, Andy. 2022. <span>“Variational Inference for MRP with Reliable
Posterior Distributions.”</span> October 10, 2022. <a href="https://andytimm.github.io/posts/Variational MRP Pt1/variational_mrp_pt1.html">https://andytimm.github.io/posts/Variational
MRP Pt1/variational_mrp_pt1.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/andytimm\.github\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>