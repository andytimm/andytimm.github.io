<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.126">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Andy Timm">
<meta name="dcterms.date" content="2019-07-03">

<title>Andy Timm - BART with varying intercepts in the MRP framework</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Andy Timm - BART with varying intercepts in the MRP framework">
<meta property="og:description" content="This is the first of a few posts about some of the substantive and modeling findings from my master’s thesis, where I use Bayesian Additive Regression Trees (BART) and Poststratification to model…">
<meta property="og:site-name" content="Andy Timm">
<meta name="twitter:title" content="Andy Timm - BART with varying intercepts in the MRP framework">
<meta name="twitter:description" content="This is the first of a few posts about some of the substantive and modeling findings from my master’s thesis, where I use Bayesian Additive Regression Trees (BART) and Poststratification to model…">
<meta name="twitter:creator" content="@andy_timm">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Andy Timm</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">About</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects.html">Personal Projects</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../software.html">Software</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html">Not Yet Updated Blog</a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">BART with varying intercepts in the MRP framework</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">from_old_website</div>
                <div class="quarto-category">MRP</div>
                <div class="quarto-category">BART</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Authors</div>
      <div class="quarto-title-meta-contents">
               <p>Andy Timm </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 3, 2019</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#choosing-a-prediction-model-for-mrp" id="toc-choosing-a-prediction-model-for-mrp" class="nav-link active" data-scroll-target="#choosing-a-prediction-model-for-mrp">Choosing a prediction model for MRP</a></li>
  <li><a href="#a-quick-review-of-multilevel-regression-and-poststratification" id="toc-a-quick-review-of-multilevel-regression-and-poststratification" class="nav-link" data-scroll-target="#a-quick-review-of-multilevel-regression-and-poststratification">A Quick Review of Multilevel Regression and Poststratification</a></li>
  <li><a href="#bart" id="toc-bart" class="nav-link" data-scroll-target="#bart">BART</a></li>
  <li><a href="#bart-vi" id="toc-bart-vi" class="nav-link" data-scroll-target="#bart-vi">BART-vi</a></li>
  <li><a href="#comparing-the-predictions-of-the-two" id="toc-comparing-the-predictions-of-the-two" class="nav-link" data-scroll-target="#comparing-the-predictions-of-the-two">Comparing the predictions of the two</a></li>
  <li><a href="#next-steps" id="toc-next-steps" class="nav-link" data-scroll-target="#next-steps">Next steps</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>This is the first of a few posts about some of the substantive and modeling findings from my master’s thesis, where I use Bayesian Additive Regression Trees (BART) and Poststratification to model support for a border wall from 2015-2019. In this post I explore some of the properties of using BART with varying intercepts (BART-vi) within the MRP framework.</p>
<!--more-->
<section id="choosing-a-prediction-model-for-mrp" class="level2">
<h2 class="anchored" data-anchor-id="choosing-a-prediction-model-for-mrp">Choosing a prediction model for MRP</h2>
<p>Multilevel Regression and Poststratification has seen huge success as a tool for obtaining accurate estimates of public opinion in small areas using national surveys. As the name would suggest, the most common tool used for the modeling step of these models are multilevel regressions, often Bayesian multilevel ones. The key intuition here is that pooling data across levels of predictors like state makes much more efficient use of the underlying data, which leads to more accurate estimates. However, there is no strict requirement that the models used here be multilevel regressions, it’s simply an efficient and stable way to get regularized predictions using quite a large set of predictors. Recently, academic work has begun to explore using a wide class of machine learning algorithms as the predictive component in this framework. Andrew Gelman calls this RRP: <a href="https://statmodeling.stat.columbia.edu/2018/05/19/regularized-prediction-poststratification-generalization-mister-p/">Regularized Regression and Poststratification</a>.</p>
<p>One particularly promising alternative prediction algorithm is <a href="https://arxiv.org/abs/0806.3286">BART</a>, which puts the high accuracy of tree-based algorithms like random forests or gradient boosting into a Bayesian framework. This has a number of appealing advantages compared to other machine learning options, especially for RRP. First, unlike other algorithms which might not have clear measures of their uncertainty or confidence intervals around their predictions, BART approximates a full posterior distribution. Second, BART has a number of prior and hyperparameter choices that have been shown to be highly effective in a wide variety of settings, somewhat reducing the need for parameter search. Finally, BART runs fast, especially when compared to the Bayesian multilevel models commonly used for MRP.</p>
<p>Of course, BART models are not without their disadvantages. First and foremost, there is currently only a small amount of recent work on BART models for categorical (as opposed to binary) response <a href="https://arxiv.org/abs/1701.01503">(Murray, 2019)</a>, and no public implementation of that model that I am aware of. In my case, this means modeling the border wall question as binary “support vs.&nbsp;oppose”, as opposed to the three categories “support, oppose, don’t know”. Given the salience of the issue, only 3.1% of people responded “Don’t Know”, so this is a relatively minor loss. However, for questions like the formerly crowded 2020 democratic primary, or a general election where third parties play a major role, this could be a much more serious loss.</p>
<p>While only a small amount of work has compared the two so far, estimates using BART appear to slightly outperform those using multilevel models. For example, <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/ajps.12361">Montgomery &amp; Olivella (2018)</a> compared using BART to <a href="http://www.stat.columbia.edu/~gelman/research/published/misterp.pdf">Gelman &amp; Ghitza’s (2013)</a>’s fairly complex multilevel model, finding the predictions were incredibly similar, being as much as .97 correlated. As they note however, their BART model produced these results both without large amounts of iteration on model form (which has been a constant challenge for MRP), and producing such estimates orders of magnitude faster. Similarly, <a href="https://www.cambridge.org/core/journals/american-political-science-review/article/barp-improving-mister-p-using-bayesian-additive-regression-trees/630866EB47F9366EDB3C22CFD951BB6F">Bisbee (2019)</a> finds across 89 different datasets that BART and MRP produced very similar estimates, but BART’s were of slightly higher quality, both by Mean Absolute Error (MAE) and Interstate Correlation (a measure of how well the state level predictions from a model using national surveys line up with state level polls). Ending his article, Bisbee writes “One avenue of future research might focus on variants of Bayesian additive regression trees that embed a multilevel component, likely providing further improvements as the best of both worlds.”</p>
<p>This is exactly what I do in my thesis, using BART with varying intercepts by state to model support for a border wall by state. To present my findings around BART-vi, I’ll start by providing a brief overview of the MRP framework. Next, I’ll explain BART, and how BART-vi extends this model. Finally, I’ll build one model of each BART type, and compare them.</p>
</section>
<section id="a-quick-review-of-multilevel-regression-and-poststratification" class="level2">
<h2 class="anchored" data-anchor-id="a-quick-review-of-multilevel-regression-and-poststratification">A Quick Review of Multilevel Regression and Poststratification</h2>
<p>While I’m mostly focused on the modeling step with this post, here’s a quick review of the overall process in building a MRP/RRP model. If you want a more complete introduction, Kastellec’s <a href="https://scholar.princeton.edu/jkastellec/publications">MRP Primer</a> is a great starting point.</p>
<p>MRP or RRP cast estimation of a population quantity of interest <span class="math inline">\theta</span> as a prediction problem. That is, instead of the more traditional approach of attempting to design the initial survey to be representative of the population, MRP leans more heavily on modeling and poststratification to make the estimates representative.</p>
<p>To sketch out the steps-</p>
<ol type="1">
<li>Either gather or run a survey or collection of surveys that collect both information on the outcome of interest, <span class="math inline">y</span>, and a set of demographic and geographic predictors, <span class="math inline">\left(X_{1}, X_{2}, X_{3}, \ldots, X_{m}\right)</span>.</li>
<li>Build a poststratification table, with population counts or estimated population counts <span class="math inline">N_{j}</span> for each possible combination of the features gathered above. Each possible combination <span class="math inline">j</span> is called a cell, one of <span class="math inline">J</span> possible cells. For example, if we poststratified only on state, there would be <span class="math inline">J=51</span> (with DC) total cells; in practice, <span class="math inline">J</span> is often several thousand.</li>
<li>Build a model, usually a Bayesian multilevel regression, to predict <span class="math inline">y</span> using the demographic characteristic from the survey or set of surveys, estimating model parameters along the way.</li>
<li>Estimate <span class="math inline">y</span> for each cell in the poststratification table, using the model built on the sample.</li>
<li>Aggregate the cells to the population of interest, weighting by the <span class="math inline">N_{j}</span>’s to obtain population level estimates: <span class="math display">\theta_{\mathrm{POP}}=\frac{\sum_{j \in J} N_{j} \theta_{j}}{\sum_{j \in J} N_{J}}</span></li>
</ol>
</section>
<section id="bart" class="level2">
<h2 class="anchored" data-anchor-id="bart">BART</h2>
<p>In this section, I review the general BART model, and discuss the hyperparameter choices I use. Proposed by <a href="https://arxiv.org/abs/0806.3286">Chipman et al, (2008)</a>, BART is a Bayesian machine learning algorithm that has seen widespread success in a wide variety of both predictive and causal inference applications. Like most machine learning models, it treats the prediction task as modeling the outcome <span class="math inline">y</span> as an unknown function <span class="math inline">f</span> of the <span class="math inline">k</span> predictors <span class="math inline">y = f(X_{k})</span>.</p>
<p>BART does with this a sum of decision trees:</p>
<p><span class="math display">Y_{k}=\sum_{j=1}^{m} g\left(\mathbf{X}_{k}, T_{j}, \mathbf{M}_{j}\right)+\epsilon_{k} \quad \epsilon_{k} \stackrel{i . i . d}{\sim} N\left(0, \sigma^{2}\right)</span></p>
<p>(To start with the continuous case, before generalizing to the binary case in a moment)</p>
<p>Each tree <span class="math inline">T_j</span> splits the data along a variety of predictors, seeking to improve the purity of outcomes in each group. For instance, in seeking to partition respondents into purer groups of support or opposition for a border wall, one natural split is that of white vs.&nbsp;nonwhite respondents, after which a further split by education might further partition the white node. At the end of fitting such a tree, there are <span class="math inline">b_{j}</span> terminal nodes (nodes at the bottom of the tree), which contain groups where the average outcome <span class="math inline">\mu_{j}</span> should be purer due to iterative splitting. This iterative splitting is equivalent to the modeling of interaction effects, and combining many such trees allows for flexible and highly non-linear functions of the predictors to be calculated. Each data point <span class="math inline">x</span> is thought of as assigned to one such terminal node for each tree, which captures <span class="math inline">E(y \vert x)</span>, with the collection of <span class="math inline">u_{j}</span>’s referred to collectively as <span class="math inline">M</span>. Together, <span class="math inline">m</span> such trees are fit to residual errors from an initial baseline prediction iteratively, ensuring that the trees are grown in varying structures that predict well for different parts of the covariate space, not just split on the same features producing identical predictions.</p>
<p>To fit such trees to the data and not overfit, BART utilizes a Bayesian framework, placing priors on tree structure, terminal node parameters, and variance, <span class="math inline">\sigma^2</span>. The prior for the <span class="math inline">u_{j}</span> and <span class="math inline">\sigma^2</span> are:</p>
<p><span class="math display">\begin{aligned} \mu_{j} | T_{j} &amp; \sim N\left(\mu, \sigma_{\mu}^{2}\right) \\ \sigma^{2} &amp; \sim I G\left(\frac{\nu}{2}, \frac{\nu \lambda}{2}\right) \end{aligned}</span></p>
<p>Where <span class="math inline">I G(\alpha, \beta)</span> is the inverse gamma distribution with shape parameter <span class="math inline">\alpha</span> and rate <span class="math inline">\beta</span>. The priors on the tree structure can be thought of as having 3 components. First, there is a prior on the probability that a tree of depth <span class="math inline">d = 0,1,2...</span> is not terminal, which is <span class="math inline">\alpha(1+d)^{-\beta}</span>, with <span class="math inline">\alpha \in(0,1) \text { and } \beta \in[0, \infty)</span>. This <span class="math inline">\alpha</span> controls how likely a terminal node is to be split, with smaller values indicating a lower likelihood of split, and <span class="math inline">\beta</span> controls the number of terminal nodes, larger <span class="math inline">\beta</span> implying more nodes. The second prior on the trees is on the distribution used to choose which covariate is split on. The final prior on the trees is on the value of the chosen splitting covariate at which to split. For both these later parameters, a common choice (and the one dbarts makes) is a simple discrete uniform distribution.</p>
<p>This set of priors also requires choosing the <span class="math inline">m, \alpha, \beta, \mu_{\mu}, \sigma, \nu</span> and <span class="math inline">\lambda</span> hyperparameters, which can be chosen via cross-validation or simply set to defaults. In general, the past literature on BART finds that the defaults developed by Mculloch work quite well in a surprisingly large number of contexts <a href="https://deepblue.lib.umich.edu/handle/2027.42/147594">(Tan, 2018)</a>. More specifically in the MRP context, both <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/ajps.12361">Montgomery &amp; Olivella (2018)</a> and <a href="https://www.cambridge.org/core/journals/american-political-science-review/article/barp-improving-mister-p-using-bayesian-additive-regression-trees/630866EB47F9366EDB3C22CFD951BB6F">Bisbee (2019)</a> found little reason to utilize non-default hyperparameter choices after reasonable search. For completeness, however, I ran a small number of hyperparameter searches on my complete records data, as recommended by the author of the <a href="https://cran.r-project.org/web/packages/dbarts/index.html">dbarts</a> package. Similar to prior work, I found little reason to diverge from the defaults suggested by Chipman et al, and implemented in dbarts, although I did ultimately go with <span class="math inline">m = 200</span> trees as Chipman et al.&nbsp;suggest, not the <span class="math inline">m = 75</span> default in dbarts. For a full derivation of these choices and their resultant properties, see <a href="https://arxiv.org/abs/0806.3286">Chipman et al.&nbsp;(2008)</a> or <a href="https://deepblue.lib.umich.edu/handle/2027.42/147594">(Tan, 2018)</a>.</p>
<p>A final modification of this formulation of BART is needed for binary outcomes. For binary outcomes, BART uses the probit link function to model the relationship between <span class="math inline">X</span> and <span class="math inline">y</span>:</p>
<p><span class="math display">P\left(Y_{k}=1 | \mathbf{X}_{k}\right)=\Phi\left[G\left(\mathbf{X}_{k}\right)\right]</span></p>
<p>where <span class="math inline">\Phi[.]</span> is the cumulative distribution function of a standard normal distribution, and <span class="math inline">G</span> is the full BART model we saw earlier. This slightly modifies steps for drawing from the posterior distribution, as discussed further in <a href="https://arxiv.org/abs/0806.3286">Chipman et al.&nbsp;(2008)</a>.</p>
</section>
<section id="bart-vi" class="level2">
<h2 class="anchored" data-anchor-id="bart-vi">BART-vi</h2>
<p>To the best of my knowledge, no prior work has utilized BART with varying intercepts (BART-vi) in the MRP framework. Given the huge amount of prior work on MRP that leverages a large set of varying intercepts, this seems like a natural extension. This modifies the BART predictor for binary outcomes to</p>
<p><span class="math inline">P\left(Y_{k}=1 | \mathbf{X}_{k}\right)=\Phi\left[G\left(\mathbf{X}_{k}\right) + \alpha_{k}\right]</span></p>
<p>with <span class="math inline">a_{k} \sim N\left(0, \tau^{2}\right)</span>. Critically, this also removes the varying intercept variable from the choice of possible features to split on, modeling it purely as a varying intercept. Given that the <a href="https://cran.r-project.org/web/packages/dbarts/index.html">dbarts</a> package which I use currently only supports 1 varying intercept, the natural choice is the state variable, as it both has the most categories and is one of the original motivations for varying intercepts in MRP work. All the old priors and hyperparameters remain the same, and dbarts places an additional cauchy prior on <span class="math inline">\tau^{2}</span>. While this cauchy prior is much less informative than the half-t, half-normal, or other priors typically used for MRP, at this time it is not possible to modify the prior choice except to a gamma distribution which is also not ideal. Future work could consider fitting this type of model with the more informative priors favored by the MRP literature for random effects, although such an improvement would require a time investment in learning to modify the c++ codebase of dbarts.</p>
</section>
<section id="comparing-the-predictions-of-the-two" class="level2">
<h2 class="anchored" data-anchor-id="comparing-the-predictions-of-the-two">Comparing the predictions of the two</h2>
<p>I provide two forms of evaluation for BART-vi vs regular BART, a quantitative assessment based on 10-fold cross validation, and a graphical/qualitative comparison of state level estimates resulting from the two.</p>
<p>To test the performance of this modification, I fit BART with and without varying intercept on state to the same <span class="math inline">m = 50</span> imputed<sup><a href="#imputationnote">1</a></sup> datasets, using 10-fold cross validation within each dataset. Overall, while both models are extremely accurate, the BART-vi model slightly outperforms the regular BART model without varying intercepts in terms of RMSE, MSE, and AUC on average. Of course, given that this is a test of predictive accuracy before the final poststratification, this isn’t a full validation of BART-vi’s predictive superiority in the MRP context. However, this is consistent with <a href="https://deepblue.lib.umich.edu/handle/2027.42/147594">(Tan, 2018)</a>’s result in a more extensive set of simulation studies that there are small gains in accuracy to be had with BART-vi when random effects are used with an appropriate grouping variable. To make such a comparison completely rigorously, one would need to fit both types of models on a dataset with a ground truth such as vote share, poststratify, and then contrast their properties relative to that ground truth, not simply compare predictive accuracy on the initial set of surveys. However, as this is not possible for the border wall question, I take this as a rough suggestion that BART-vi may preform better in my context, and possibly in others.</p>
<p>Plotting a comparison of the state-level median prediction from the two models after poststratification shows a familiar pattern of pooling. The BART-vi estimates are pulled somewhat towards the grand mean, whereas the ones without varying intercepts are a bit more spread out. Note, however, that we don’t see the sort of <a href="https://twitter.com/rlmcelreath/status/878268413952634880/photo/1">idealized pooling</a> trend often shown in textbook examples of multilevel models, with non-multilevel predictions that are uniformly higher above the grand mean and uniformly lower below it compared to the multilevel predictions. This is due to the simple BART model modeling much more complex interactions based on the state variables than a single level regression.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="bart-compare.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">BART models with and without pooling</figcaption><p></p>
</figure>
</div>
<p>One particularly interesting qualitative example to illustrate the differences between the models is that of DC, which is both a small state, and an incredibly liberal one. This presents a dilemma from the perspective of varying intercepts pooling: on the one hand, with only 94 observations in the full data, we should want some pooling on DC’s estimate. On the other, DC genuinely is exceptionally liberal, which suggests that pooling it too much could hurt predictive performance. While both already somewhat regularize the 13% raw approval for the wall in our aggregated polls, BART-vi does so much more. Thus, while the average predictions are of higher quality with BART-vi, the DC and other extreme state predictions are superior without random effects. Most prior MRP work has been happy to make this sort of trade off, and based on the rough accuracy comparisons I’ve made, this appears to work well for my data and my BART model as well.</p>
<p>Comparing the full posterior distributions of the two models below, we can also see BART-vi has noticably wider 50 and 90% intervals as well (the dot indicates the median, the thick bar is the 50% interval, and the thinnest bar is the 90% one). Like with my CV testing, a complete sense of which level of uncertainty provided here is appropriate will have to wait for future MRP work that leverages data with a ground truth. However, in many cases, the fixed effects intervals border on what I’d call concerningly small- I wouldn’t be suprised if the coverage properties of the BART-vi intervals are better.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="full-post.jpeg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Full Posterior of the Two Models</figcaption><p></p>
</figure>
</div>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next steps</h2>
<p>Given that my work shows BART-vi having some desirable properties for RRP, what might be some extensions to explore next?</p>
<p>A first obvious step might be explore this type of model on data where we do have a ground truth like voter turnout, or vote share. For a more extensive comparison, one could leverage Bisbee (2019)’s replication data, which would hopefully provide a more complete answer to whether this strategy works well in general.</p>
<p>Probably the most theoretically interesting question would be how to handle the possibility of multiple random intercepts, if dbarts or another package eventually implements them. This represents a tradeoff between the benefits of flexible Bayesian non-parametrics in BART, and the pooling behavior of varying intercepts. Initially, I thought it was entirely feasible that the BART-vi I fit would have worse predictive accuracy, given the potential benefits of splitting on state. However, given that I utilize both 2012 vote share and region as predictors, it seems that the model still had ample state level information. However, as we pooled across more variables, this would increasingly weaken the non-parametric component of the BART-vi model. In this scenario, would pooling across demographic predictors that have many fewer categories make sense? While future work will have to tell, my guess is that the answer might be that only state or other geographic variables benefit from pooling.</p>
<hr>
<p><a name="imputationnote">1</a>: Given my data had a relatively large proportion of respondents who refused to answer at least 1 demographic question (10.54%), I also explored imputing the missing characteristics using a variety of different approaches. The full details of that are coming in another post, but I ran 10-fold CV on the imputations so that the evaluation would more fully mirror my final modeling scenario.</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div quarto-reuse="quarto-reuse" class="quarto-appendix-contents"><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{timm2019,
  author = {Andy Timm},
  editor = {},
  title = {BART with Varying Intercepts in the {MRP} Framework},
  date = {2019-07-03},
  url = {https://andytimm.github.io/2020-03-06-BART-vi.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-timm2019" class="csl-entry quarto-appendix-citeas" role="doc-biblioentry">
Andy Timm. 2019. <span>“BART with Varying Intercepts in the MRP
Framework.”</span> July 3, 2019. <a href="https://andytimm.github.io/2020-03-06-BART-vi.html">https://andytimm.github.io/2020-03-06-BART-vi.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>