<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.475">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Andy Timm">
<meta name="dcterms.date" content="2023-06-17">

<title>Andy Timm - Variational Inference for MRP with Reliable Posterior Distributions</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Andy Timm - Variational Inference for MRP with Reliable Posterior Distributions">
<meta property="og:description" content="Part 6- Diagnostics">
<meta property="og:site-name" content="Andy Timm">
<meta name="twitter:title" content="Andy Timm - Variational Inference for MRP with Reliable Posterior Distributions">
<meta name="twitter:description" content="Part 6- Diagnostics">
<meta name="twitter:creator" content="@andy_timm">
<meta name="twitter:site" content="@andy_timm">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Andy Timm</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects.html">
 <span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../software.html">
 <span class="menu-text">Software</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html">
 <span class="menu-text">Rarely Updated Blog</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Variational Inference for MRP with Reliable Posterior Distributions</h1>
            <p class="subtitle lead">Part 6- Diagnostics</p>
                                <div class="quarto-categories">
                <div class="quarto-category">MRP</div>
                <div class="quarto-category">Variational Inference</div>
                <div class="quarto-category">Diagnostics</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Andy Timm </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">June 17, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#looking-at-our-loss-function" id="toc-looking-at-our-loss-function" class="nav-link active" data-scroll-target="#looking-at-our-loss-function">Looking at our loss function</a></li>
  <li><a href="#the-majesty-of-hatk" id="toc-the-majesty-of-hatk" class="nav-link" data-scroll-target="#the-majesty-of-hatk">The majesty of <span class="math inline">\hat{k}</span></a>
  <ul>
  <li><a href="#problem-case-1-importance-sampling-neq-direct-variational-inference" id="toc-problem-case-1-importance-sampling-neq-direct-variational-inference" class="nav-link" data-scroll-target="#problem-case-1-importance-sampling-neq-direct-variational-inference">Problem Case 1: Importance sampling <span class="math inline">\neq</span> direct variational inference</a></li>
  <li><a href="#problem-case-2-hatk-is-a-local-diagnostic" id="toc-problem-case-2-hatk-is-a-local-diagnostic" class="nav-link" data-scroll-target="#problem-case-2-hatk-is-a-local-diagnostic">Problem Case 2: <span class="math inline">\hat{k}</span> is a local diagnostic</a></li>
  <li><a href="#problem-case-3-hatk-is-a-joint-posterior-level-tool" id="toc-problem-case-3-hatk-is-a-joint-posterior-level-tool" class="nav-link" data-scroll-target="#problem-case-3-hatk-is-a-joint-posterior-level-tool">Problem Case 3: <span class="math inline">\hat{k}</span> is a joint posterior level tool</a></li>
  </ul></li>
  <li><a href="#wasserstein-bounds" id="toc-wasserstein-bounds" class="nav-link" data-scroll-target="#wasserstein-bounds">Wasserstein Bounds</a></li>
  <li><a href="#mcmc-based-diagnostics-whats-old-is-new-again" id="toc-mcmc-based-diagnostics-whats-old-is-new-again" class="nav-link" data-scroll-target="#mcmc-based-diagnostics-whats-old-is-new-again">MCMC based diagnostics; what’s old is new again</a>
  <ul>
  <li><a href="#mcmc-can-be-practically-useful-even-when-slow" id="toc-mcmc-can-be-practically-useful-even-when-slow" class="nav-link" data-scroll-target="#mcmc-can-be-practically-useful-even-when-slow">MCMC can be practically useful even when slow</a></li>
  <li><a href="#taddaa" id="toc-taddaa" class="nav-link" data-scroll-target="#taddaa">TADDAA</a></li>
  </ul></li>
  <li><a href="#diagnostics-that-dont-spark-joy" id="toc-diagnostics-that-dont-spark-joy" class="nav-link" data-scroll-target="#diagnostics-that-dont-spark-joy">Diagnostics that don’t spark joy</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>This is section 6 in my series on using Variational Inference to speed up relatively complex Bayesian models like Multilevel Regression and Poststratification without the approximation being of disastrously poor quality.</p>
<p>The general structure for this post and the posts around it will be to describe a problem with VI, and then describe how that problem can be fixed to some degree. Collectively, all the small improvements in these four posts will go a long way towards more robust variational inference. I’ll also have a grab bag at the end of other interesting ideas from the literature I think are cool, but maybe not as important or interesting to me as the 3 below.</p>
<p>In the <a href="https://andytimm.github.io/posts/Variational%20MRP%20Pt5/variational_mrp_5.html">last post</a> we looked at normalizing flows, a way to leverage neural networks to learn significantly more expressive variational families in a way that adapt to specific problems.</p>
<p>In this post, we’ll explore different diagnostics for variational inference, ranging from simple statistics that are easy to calculate as we fit our approximation to solving the problem in parallel with MCMC to compare and contrast. Some recurring themes will be aiming to be precise about what constitutes failure under each diagnostic tool, and providing intuition building examples where each diagnostic will fail to do anything useful. While no single diagnostic provides strong guarantees of variational inference’s correctness on their own, taken together the tools in this post broaden our ability to know when our models fall short.</p>
<p>The rough plan for the series is as follows:</p>
<ol type="1">
<li>Introducing the Problem- Why is VI useful, why VI can produce spherical cows</li>
<li>How far does iteration on classic VI algorithms like mean-field and full-rank get us?</li>
<li>Problem 1: KL-D prefers exclusive solutions; are there alternatives?</li>
<li>Problem 2: Not all VI samples are of equal utility; can we weight them cleverly?</li>
<li>Problem 3: How can we get deeply flexible variational approximations; are Normalizing Flows the answer?</li>
<li><strong>(This post)</strong> Problem 4: How can we know when VI is wrong? Are there useful error bounds?</li>
<li>Putting the workflow all together</li>
</ol>
<section id="looking-at-our-loss-function" class="level1">
<h1>Looking at our loss function</h1>
<p>One logical place to start with diagnostics is to discuss what we can and can’t infer from our optimization objectives like an ELBO or CUBO.</p>
<p>In training a model with variational inference some common stopping rule choices are either to just run optimization for a fixed number of iterations, or to stop when relative changes in the loss have slowed, indicating convergence of the optimization to a local minimum. So we can at least look at changes in the ELBO/CUBO/other loss to know if our approximation has hit a local minimum yet.</p>
<p>Unfortunately, that’s about all monitoring the loss can tell us. Recall that An unknown, multiplicative constant exists in <span class="math inline">p(z,x) \propto p(z|x)</span> that changes as reparameterize our model; thus, we can’t compare two different models on the same objective and expect their ELBO or similar loss values to be comparable. So the typical ML strategy of “which model achieves lower loss” is pretty much out here.</p>
<p>Also, the loss values themselves aren’t particularly meaningful: there’s no way to interpret a given ELBO as indicating a good approximation, for example. This generally stems from our bounds being bounds, not directly optimizing the quantity we want to optimize. While they’re definitely degenerate cases, there are even some fun counter examples I’ll show in a second where you can make the ELBO/CUBO arbitrarily low, while still allowing the posterior mean or standard deviation to be arbitrarily wrong!</p>
</section>
<section id="the-majesty-of-hatk" class="level1">
<h1>The majesty of <span class="math inline">\hat{k}</span></h1>
<p>So if we can’t just look at our loss, what can we look at? One broadly applicable diagnostic tool is <span class="math inline">\hat{k}</span>, which we already introduced in the post on using importance sampling to improve variational inference.</p>
<p>As a several sentence refresher, Pareto smoothed importance sampling (PSIS) proposes to stabilize importance ratios <span class="math inline">r(\theta)</span> used in importance sampling by modeling the tail of the distribution as a generalized Pareto distribution:</p>
<p><span class="math display">
\frac{1}{\sigma} \left(1 + k\frac{r - \tau}{\sigma} \right)^{-1/k-1}
</span> where <span class="math inline">\tau</span> is a lower bound parameter, which in our case defines how many ratios from the tail we’ll actually model. <span class="math inline">\sigma</span> is a scale parameter, and <span class="math inline">k</span> is a unconstrained shape parameter.</p>
<p>To see how this provides a natural diagnostic for importance sampling, it’s useful to know that importance sampling depends on how many moments <span class="math inline">r(\theta)</span> has- for example, if at least two moments exist, the vanilla IS estimator has finite variance (which is obviously required, but no guarantee of performance since it might be finite but massive). The GPD has <span class="math inline">k^{-1}</span> finite fractional moments when <span class="math inline">k &gt; 0</span>. <a href="https://arxiv.org/abs/1507.02646">Vehtari et Al. (2015)</a> show through extensive theoretical digging and simulations that PSIS works fantastically when <span class="math inline">\hat{k} &lt; .5</span>. and acceptably if <span class="math inline">.5 &lt; \hat{k} &lt; .7</span>. Beyond <span class="math inline">\hat{k} = .7</span> there the number of samples needed rapidly become impractically large.</p>
<p>Why should we think <span class="math inline">\hat{k}</span> is a relevant diagnostic for variational inference? <a href="https://arxiv.org/abs/1511.01437">Chaterjee and Draconis (2018)</a> showed that for a given accuracy, how big <span class="math inline">S</span> needs to be for importance sampling more broadly depends on how close <span class="math inline">q(x)</span> is to <span class="math inline">p(x)</span> in KL distance- we need to satisfy <span class="math inline">log(S) \geq \mathbb{E}_{\theta \sim q(x)}[r(\theta)log(r(\theta))]</span> to get reasonable accuracy. So a good <span class="math inline">\hat{k}</span> indicates importance sampling is feasible, which in tern indicates that <span class="math inline">q(x)</span> is likely close to <span class="math inline">p(x)</span> in KL Divergence- exactly what we’re hoping to get at!</p>
<p>Fleshing out the use of <span class="math inline">\hat{k}</span> as a VI diagnostic was done by <a href="https://arxiv.org/abs/1802.02538">Yao et al.&nbsp;(2018)</a>, who generally show that high values of <span class="math inline">\hat{k}</span> do generally map onto posterior approximations with variational inference being quite poor. This is really useful, and generally maps well on to my experience- if <span class="math inline">\hat{k}</span> is bigger than .7, you probably need to go back to the drawing board on how you’re fitting your VI.</p>
<p>What I want to stress though, is that the inverse isn’t broadly true- a low <span class="math inline">\hat{k}</span> isn’t necessarily a guarantee the VI approximation is good. Let’s look at a couple different ways this can happen.</p>
<section id="problem-case-1-importance-sampling-neq-direct-variational-inference" class="level2">
<h2 class="anchored" data-anchor-id="problem-case-1-importance-sampling-neq-direct-variational-inference">Problem Case 1: Importance sampling <span class="math inline">\neq</span> direct variational inference</h2>
<p>We should keep in mind that <span class="math inline">\hat{k}</span> is ultimately a diagnostic tool for importance sampling, and in cases where the needs of importance sampling and simple variational inference diverge, <span class="math inline">\hat{k}</span> can give a misleading answer.</p>
<p>Let’s re-use an example from the importance sampling post to illustrate this. What happens if we approximate the red distribution below with the green one?</p>
<div class="cell">

</div>
<div class="cell">

</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>mixture <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> normals)) <span class="sc">+</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> normals), <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> mean_seeking_kl), <span class="at">color =</span> <span class="st">"green"</span>) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"The green approxmiation is great for IS, terrible on it's own"</span>) <span class="sc">+</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="variational_mrp_pt6_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The green distribution here is a prime candidate to importance sample to approximate the red one- it coves all the needed mass, and we can massively down weight the irrelevant points in the center. On the other hand, this’d be a really, really bad variational approximation to use raw, since it has a ton of mass between the two modes which will blow up our loss. Because the needs of PSIS-based estimators and unadjusted VI diverge, <span class="math inline">\hat{k}</span> is low, but the approximation would be pretty bad:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>importance_ratios <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="at">q_x =</span> <span class="fu">rnorm</span>(<span class="dv">200000</span>,<span class="dv">9</span>,<span class="dv">4</span>),</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="at">p_x =</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">100000</span>,<span class="dv">3</span>,<span class="dv">1</span>),<span class="fu">rnorm</span>(<span class="dv">100000</span>,<span class="dv">15</span>,<span class="dv">2</span>)),</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="at">ratios =</span> (.<span class="dv">5</span><span class="sc">*</span>(<span class="fu">dnorm</span>(q_x,<span class="dv">3</span>,<span class="dv">1</span>)) <span class="sc">+</span> .<span class="dv">5</span><span class="sc">*</span>(<span class="fu">dnorm</span>(q_x,<span class="dv">15</span>,<span class="dv">2</span>)))<span class="sc">/</span><span class="fu">dnorm</span>(q_x,<span class="dv">9</span>,<span class="dv">4</span>))</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>psis_result <span class="ot">&lt;-</span> <span class="fu">psis</span>(<span class="fu">log</span>(importance_ratios<span class="sc">$</span>ratios),</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>                       <span class="at">r_eff =</span> <span class="cn">NA</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>psis_result<span class="sc">$</span>diagnostics<span class="sc">$</span>pareto_k</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -1.737515</code></pre>
</div>
</div>
<p>So our <span class="math inline">\hat{k}</span> says everything is beautiful, but in reality it’s really only a happy time for PSIS, not the raw VI estimator. This ultimately isn’t the most concerning failure mode: if you do the work to calculate <span class="math inline">\hat{k}</span>, you’re pretty much ready to use PSIS to improve your variational inference anyway. That said, this should provide intuition that <span class="math inline">\hat{k}</span> isn’t in general super well equipped to tell you much about non-IS augmented VI.</p>
</section>
<section id="problem-case-2-hatk-is-a-local-diagnostic" class="level2">
<h2 class="anchored" data-anchor-id="problem-case-2-hatk-is-a-local-diagnostic">Problem Case 2: <span class="math inline">\hat{k}</span> is a local diagnostic</h2>
<p><span class="math inline">\hat{k}</span> inherits a common issue with most KL Divergence adjacent metrics: it’s ultimately something we evaluate locally, so if there’s a part of the posterior totally unknown to our <span class="math inline">q(x)</span>, it won’t be able to tell you what you’re missing.</p>
<p>We already used 1 example from the importance sampling post, so let’s keep that moving. What do you think will happen with <span class="math inline">\hat{k}</span> with the green approximation below that misses a whole mode?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>mixture <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> normals)) <span class="sc">+</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> normals), <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> mode_seeking_kl), <span class="at">color =</span> <span class="st">"green"</span>) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"We're missing a whole mode here"</span>) <span class="sc">+</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="variational_mrp_pt6_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>If you guessed <span class="math inline">\hat{k}</span> will say everything is perfect when it’s not, you’re correct:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>second_importance_ratios <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="at">q_x =</span> <span class="fu">rnorm</span>(<span class="dv">200000</span>,<span class="fl">3.5</span>,<span class="dv">1</span>),</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="at">p_x =</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">100000</span>,<span class="dv">3</span>,<span class="dv">1</span>),<span class="fu">rnorm</span>(<span class="dv">100000</span>,<span class="dv">15</span>,<span class="dv">2</span>)),</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Notice: these density calls are at the points defined by q(x)!</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="at">ratios =</span> (.<span class="dv">5</span><span class="sc">*</span>(<span class="fu">dnorm</span>(q_x,<span class="dv">3</span>,<span class="dv">1</span>)) <span class="sc">+</span> .<span class="dv">5</span><span class="sc">*</span>(<span class="fu">dnorm</span>(q_x,<span class="dv">15</span>,<span class="dv">2</span>)))<span class="sc">/</span><span class="fu">dnorm</span>(q_x,<span class="fl">3.5</span>,<span class="dv">1</span>))</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>psis_result_2 <span class="ot">&lt;-</span> <span class="fu">psis</span>(<span class="fu">log</span>(second_importance_ratios<span class="sc">$</span>ratios),</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>                       <span class="at">r_eff =</span> <span class="cn">NA</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>psis_result_2<span class="sc">$</span>diagnostics<span class="sc">$</span>pareto_k</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.07343881</code></pre>
</div>
</div>
<p>That’s… not great. Since we evaluate the importance ratio and thus eventually <span class="math inline">\hat{k}</span> at the collection of values in <span class="math inline">q(x)</span>, the diagnostic has no real way to know we’re missing an entire mode, and unlike in the above case there’s no easy fix here.</p>
<p>Another interesting question this example raises is what happens in high dimensions, where it’s much less intuitive what “missing one or several modes” looks like. Just by increasing the sd of the normal <span class="math inline">q(x)</span> a little in the example, we see a sudden, large increase in <span class="math inline">\hat{k}</span>;</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>third_importance_ratios <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="at">q_x =</span> <span class="fu">rnorm</span>(<span class="dv">200000</span>,<span class="fl">3.5</span>,<span class="dv">2</span>),</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="at">p_x =</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">100000</span>,<span class="dv">3</span>,<span class="dv">1</span>),<span class="fu">rnorm</span>(<span class="dv">100000</span>,<span class="dv">15</span>,<span class="dv">2</span>)),</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="at">ratios =</span> (.<span class="dv">5</span><span class="sc">*</span>(<span class="fu">dnorm</span>(q_x,<span class="dv">3</span>,<span class="dv">1</span>)) <span class="sc">+</span> .<span class="dv">5</span><span class="sc">*</span>(<span class="fu">dnorm</span>(q_x,<span class="dv">15</span>,<span class="dv">2</span>)))<span class="sc">/</span><span class="fu">dnorm</span>(q_x,<span class="fl">3.5</span>,<span class="dv">2</span>))</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>psis_result_3 <span class="ot">&lt;-</span> <span class="fu">psis</span>(<span class="fu">log</span>(third_importance_ratios<span class="sc">$</span>ratios),</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>                       <span class="at">r_eff =</span> <span class="cn">NA</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>psis_result_3<span class="sc">$</span>diagnostics<span class="sc">$</span>pareto_k</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3.70381</code></pre>
</div>
</div>
<p>similar sudden shifts in <span class="math inline">\hat{k}</span> can frequently occur as you increase the dimension of a posterior you’re approximating- intuitively, the mass you do and don’t know about becomes much harder to keep track of in high dimensions and for complex posteriors. This can lead to <span class="math inline">\hat{k}</span> being a bit less stable than you’d like over different initializations or other slight modifications of a VI model, with this pattern being common both in my own applications and documented in several papers like <a href="https://arxiv.org/abs/2302.12419">Wang et al.&nbsp;(2023)</a>’s testing.</p>
</section>
<section id="problem-case-3-hatk-is-a-joint-posterior-level-tool" class="level2">
<h2 class="anchored" data-anchor-id="problem-case-3-hatk-is-a-joint-posterior-level-tool">Problem Case 3: <span class="math inline">\hat{k}</span> is a joint posterior level tool</h2>
<p>A final, more conceptual problem with <span class="math inline">\hat{k}</span> that <a href="https://arxiv.org/abs/1802.02538">Yao et al.&nbsp;(2018)</a> point out is that it’s ultimately a diagnostic of the joint posterior, not the specific marginal or summary statistic you may ultimately care about.</p>
<p>Variational inference is hard: we often know that the overall posterior approximation is deeply flawed, but it may be up to the task of representing some metrics we care about correctly enough. For example, in the MRP example I introduced earlier in the series, the mean-field variational inference fit was reasonable at representing the state-level means, but garbage at pretty much anything related to uncertainty. The <span class="math inline">\hat{k}</span> from that model was greater than 2, so we clearly know the broader posterior approximation was poor, but <span class="math inline">\hat{k}</span> might be a false positive sign if what you really care about was just the means. For the most complicated posteriors, we should expect to spend a lot of time in this feeling of “some parts of the posterior may be good enough”, so this is a useful trap to know about.</p>
<p>…Let’s step back for a second. Since I introduced PSIS with a bunch of cases where it falls short in surprising ways, I do want to emphasize it is a very useful <em>heuristic</em> diagnostic tool in general. Large <span class="math inline">\hat{k}</span> tells you something is very likely wrong with your joint posterior, and that’s generally practically helpful information. Where we need to be cautious is in inferring whether the wrongness <span class="math inline">\hat{k}</span> picks up on is something we care about, and also in remembering that low <span class="math inline">\hat{k}</span> doesn’t provide gaurantees of correctness.</p>
</section>
</section>
<section id="wasserstein-bounds" class="level1">
<h1>Wasserstein Bounds</h1>
</section>
<section id="mcmc-based-diagnostics-whats-old-is-new-again" class="level1">
<h1>MCMC based diagnostics; what’s old is new again</h1>
<section id="mcmc-can-be-practically-useful-even-when-slow" class="level2">
<h2 class="anchored" data-anchor-id="mcmc-can-be-practically-useful-even-when-slow">MCMC can be practically useful even when slow</h2>
</section>
<section id="taddaa" class="level2">
<h2 class="anchored" data-anchor-id="taddaa">TADDAA</h2>
</section>
</section>
<section id="diagnostics-that-dont-spark-joy" class="level1">
<h1>Diagnostics that don’t spark joy</h1>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div quarto-reuse="quarto-reuse" class="quarto-appendix-contents"><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{timm2023,
  author = {Andy Timm},
  title = {Variational {Inference} for {MRP} with {Reliable} {Posterior}
    {Distributions}},
  date = {2023-06-17},
  url = {https://andytimm.github.io/variational_mrp_pt6.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-timm2023" class="csl-entry quarto-appendix-citeas" role="doc-biblioentry">
Andy Timm. 2023. <span>“Variational Inference for MRP with Reliable
Posterior Distributions.”</span> June 17, 2023. <a href="https://andytimm.github.io/variational_mrp_pt6.html">https://andytimm.github.io/variational_mrp_pt6.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>