---
layout: post
title: Better discrete choice modeling through rank ordered logits
subtitle: Or- a mathmatically correct model of a psychologically coherent concept
date: 2024-06-09
draft: True
image: imgs/gumby_distribution.webp
categories:
  - priors
  - stupid Bayesian stuff
---

![](imgs/jimmy_dunk.png){fig-align="center"}

The wonderful Jim Savage calls the MaxDiff model of discrete choice a "mathematically
incorrect model of a psychologically incoherent concept"[^1].

Despite this lovely dunk,
and some wonderful     notes explaining why MaxDiff's not great, the model remains frequently used in market
research, most prominently as implemented in [Sawtooth](https://sawtoothsoftware.com/). Why is this?

Putting aside the most obvious answers like inertia and a dim view of statistical practice in marketing, it's surprisingly hard to find a fully fleshed out explanation of the alternatives online. In this post, I remedy that, with sections for:

1. Introducing MaxDiff and its blemishes
2. Showing how the issues propagate into final model quality
3. Alternatives- Rank-Ordered Logits with ties, and connected choice graphs

# Introducing MaxDiff

If you're reading this post, you likely have some familiarity with the basics
of discrete choice models, but here's a brief refresher[^2].

We want to build a model of how real people respond to the request to make decisions
among discrete options. This could be:

 - A pollster asking which candidate(s) or political parties each respondent favors
 - A marketing firm studying preferences amongst a variety of chocolate bars
 - A political scientist asking which message voters find most convincing
 
One reasonable model[^3] for this is to say that individual $i$ making choices among
$j$ options can be inferred to have some underlying utility $\mu$ from the available
choices, and that while they usually choose their most preferred option according to
their utility function, there is some degree of randomness. The basic
model is then

$$
\mu_{ij} = \mu_{ij} + \epsilon_{ij}
$$
, where the $\mu_{ij}$ can have rich provenance (demographics and other individual traits, the context in which the decision is made, the other options available...) but is fixed, but there's some
$\epsilon_{ij}$ of randomness involved. To make this model easier to estimate, we assume
that $\epsilon_{ij}$ has a [Gumbel](https://en.wikipedia.org/wiki/Gumbel_distribution)[^4] distribution. 

Under this model, the probability that individual $i$ chooses alternative $j$ from a choice set $C_i$ is:
$$
P_{ij} = \frac{\exp(\mu_{ij})}{\sum_{k \in C_i} \exp(\mu_{ik})}
$$
This is the standard multinomial logit.

Now, suppose we have a dataset where each individual $i$ has made a choice $y_i$ from their choice set $C_i$. The likelihood of observing this dataset under the multinomial logit model is:
$$
L = \prod_i P_{iy_i} = \prod_i \frac{\exp(\mu_{iy_i})}{\sum_{k \in C_i} \exp(\mu_{ik})}
$$
The likelihood is the product of the choice probabilities for each individual's observed choice $y_i$. We can estimate the parameters of the utility function $\mu_{ij}$ by maximizing this likelihood function (or, more commonly, the log-likelihood).
This is how the single best choice data is naturally incorporated into the likelihood function. Each observation contributes a term to the likelihood based on the probability of the chosen "best" alternative under the model.

While we can (and will) push the basic logit model of this further to include respondent and choice level covariates, multilevel components, and other improvements, let's think about the pressures of gathering data here for a moment, since that'll motivate the desire for something like MaxDiff.

To estimate this, we gather respondents and ask them to choose their favorite
option amongst a given choice set. As a way to control the difficulty of making a choice while still gathering enough data,
we can limit the size of the set (choose the best of 10 items, instead of 20), and
repeat the choice task. 

Getting respondents and getting them to stick through a bunch of choice tasks is hard though,
and it's only natural to wonder: can we extract more with each choice set? One option
would be to ask the respondents to rank ALL the options at once, but if you have
a large choice set that sounds exhausting.

What if we asked people to choose their best and worst choices each time? After all, people might not have strong preferences amongst the middling 18 chocolate bars, but the best and  worst seem more memorable, and that's only 1 more choice.

And now, (stepping into the MaxDiff trap to show its allure, if you will), what if we
don't want to entirely change up our likelihood to handle the new rich source of data? What if handling ties sounds awful? Instead, what if we just treat the worsts
as the opposite of the bests, which makes a sort of sense, and simplifies the likelihood
one hell of a lot:

$$
U_{ij}^W = -U_{ij}^B = -(\mu_{ij} + \epsilon_{ij})
$$

Under this assumption, the probability of individual $i$ choosing alternative $j$ as the worst is:
$$
P_{ij}^W = \frac{\exp(-\mu_{ij})}{\sum_{k \in C_i} \exp(-\mu_{ik})}
$$

... Now we've stepped in it, and Jimmy is mad at us.

## Psycologically Incoherent

What I've introduced is the core of the MaxDiff formulation of discrete choice,
before bells and whistles are introduced. This has some deep problems though; let's start with the "psychological" ones. Human decisionmaking is an incredibly complex, not always logical
process, and we'll always be losing significant fidelity in boiling it down into
a model. Here though, I'll focus on explaining a handful of breakdowns in the relationship
between reality and the world of our models that are particularly harmful.

First, let's talk about **symmetry**. With the MaxDiff likelihood above, we're treating
the worst as equal and opposite to the best. For example, though, I don't like
Joe Biden as much as I dislike Trump[^5]. I really really like the best pizza
in Brookyln, but New York pizza is all New York pizza, it only gets so bad. This
might be a reasonable simplification in some rare cases, but it's hard to argue
that baking this into our model faithfully mirrors reality.

Also, we're not only asking them to be symmetric, we're sort of conjoining
the best and worst choice, asking them
to share the **same utility scale**. In other words, the factors that make an alternative more attractive for the best choice are assumed to make it equally less attractive for the worst choice. An easy example is something like health risks- "that sushi place gave me food poisoning" is very relevant
to my choice of worst restaurant, but the moment I have to think about food safety,
a restaurant isn't really anywhere relevant on the "best" side of the spectrum for me.
Again, you can probably think of a case where this is a fine approximation, but
in an ideal world, we won't force ourselves to weld our notions of best to our
notions of worst.

Finally, the **error variances** being treated as the same should feel pretty
strange. I'm much, much more consistent in my selection of "bests" than "worsts"-
why would I spent a bunch of time deciding which opinion of 20 is the absolute
worst and which is just 19th worst? People tend to be much less consistent, and
frankly much less engaged, with their worst choices. Why would we bake this into
our model?

Putting this all together, The simplification in estimation that comes with MaxDiff also
leaks into how the model "sees" the decision maker, and it meaningfully distorts
the map in a way that does not reflect the territory,

## Mathmatically Incorrect

# The defects are not just theoretical or cosmetic: an illustration

# Alternative #1: rank-ordered logits with connected graphs of choices

# Alternative #2: a backup plan- rank-ordered logits with ties

# Stepping Back: the utility of discrete choice more broadly

[^1]: The smiley face is a threat: it's there to make sure MaxDiff stays down :-D
[^2]: If you want more of an in-depth introduction, here are some resources I'd reccomend. First, Jim Savage's [blog post series](https://khakieconomics.github.io/2019/03/17/Logit-models-of-discrete-choice.html) is great, and does a fantastic job of explaining how our assumptions about choice making map onto the math. I also benefitted from reading Glasgow's [Interpreting Discrete Choice Models](https://www.cambridge.org/core/elements/abs/interpreting-discrete-choice-models/676EC2C0F19A3B6D932E12CC612872BC), which builds up the basics of choice models a bit more slowly. Finally, if you want something that goes much more in detail, Kenneth Train's [Discrete Choice Models with Simulation](https://eml.berkeley.edu/books/choice2.html) goes into great mathmatical detail about the models.
[^3]: I won't rehash more subtle implications of this basic model here; see the footnote above for references that explore the mind of this *Homo Economicus* more in depth. Instead, I'll mostly pull up assumptions as they become relevant for discussing MaxDiff.
[^4]: Other options are possible, but less common, and would take us too far afield, so I'll skip explaining the choice of Gumbel versus other distributions here.
[^5]: President Biden is great, it's just hard to compete with the comically malignant
and incompetent by being solid and stabilizing.