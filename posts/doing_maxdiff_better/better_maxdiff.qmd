---
layout: post
title: Better discrete choice modeling through rank ordered logits
subtitle: Or- a mathmatically correct model of a psychologically coherent concept
date: 2024-06-09
draft: True
image: imgs/fosters_kangaroo.webp
categories:
  - priors
  - stupid Bayesian stuff
---

![](imgs/jimmy_dunk.png){fig-align="center"}

The wonderful Jim Savage calls the MaxDiff model of discrete choice a "mathematically
incorrect model of a psychologically incoherent concept"[^1].

Despite this lovely dunk,
and some lovely accompanying notes explaining why MaxDiff's not great, the model remains frequently used in market
research, most prominently as implemented in [Sawtooth](https://sawtoothsoftware.com/). Why is this?

Putting aside the most obvious answers like inertia and a dim view of statistical practice in marketing, it's surprisingly hard to find a fully fleshed out explanation of the alternatives online. In this post, I do just that, with sections for:

1. Introducing MaxDiff and its blemishes
2. Showing how the issues propagate into final model quality
3. Alternatives

# Introducing MaxDiff

If you're reading this post, you likely have some familiarity with the basics
of discrete choice models, but here's a brief refresher[^2].

We want to build a model of how real people respond to the request to make decisions
among discrete options. This could be:
 - A pollster asking which candidate(s) or political parties each respondent favors
 - A marketing firm studying preferences amongst a variety of chocolate bars
 - A political scientist asking which message voters find most convincing
 
One reasonable model[^3] for this is to say that individual $i$ making choices among
$j$ options can be inferred to have some underlying utility $\mu$ from the available
choices, and that while they usually choose their most preferred option according to
their utility function, there is some degree of randomness. The basic
model is then

$$
\mu_{ij} = \mu_{ij} + \epsilon_{ij}
$$
, where the $\mu_{ij}$ can have rich provenance (demographics and other individual traits, the context in which the decision is made, the other options available...) but is fixed, but there's some
$\epsilon_{ij}$ of randomness involved. To make this model easier to estimate, we assume
that $\epsilon_{ij}$ has a [Gumbel](https://en.wikipedia.org/wiki/Gumbel_distribution)[^4] distribution. 

Under this model, the probability that individual $i$ chooses alternative $j$ from a choice set $C_i$ is:
$$
P_{ij} = \frac{\exp(\mu_{ij})}{\sum_{k \in C_i} \exp(\mu_{ik})}
$$
This is the standard multinomial logit.

Now, suppose we have a dataset where each individual $i$ has made a choice $y_i$ from their choice set $C_i$. The likelihood of observing this dataset under the multinomial logit model is:
$$
L = \prod_i P_{iy_i} = \prod_i \frac{\exp(\mu_{iy_i})}{\sum_{k \in C_i} \exp(\mu_{ik})}
$$
The likelihood is the product of the choice probabilities for each individual's observed choice $y_i$. We can estimate the parameters of the utility function $\mu_{ij}$ by maximizing this likelihood function (or, more commonly, the log-likelihood).
This is how the single best choice data is naturally incorporated into the likelihood function for the standard multinomial logit model. Each observation contributes a term to the likelihood based on the probability of the chosen "best" alternative under the model.

While we can (and will) push the basic logit model of this further to include respondent and choice level covariates, multilevel components, and other improvements, let's think about the pressures of gathering data here for a moment.

To estimate this, we gather respondents and ask them to choose their favorite
option amongst a given choice set. As a way to control the difficulty of making a choice while still gathering enough data,
we can limit the size of the set (choose the best of 10 items, instead of 20), and
repeat the choice task. 

Getting sample and getting them to stick through a bunch of choice tasks is hard though,
and it's only natural to wonder: can we extract more with each choice set? One option
would be to ask the respondents to rank ALL the options at once, but if you have
a large choice set that sounds exhausting.

What if we asked people to choose their best and worst choices each time? After all, people might not have strong preferences amongst the middling 18 chocolate bars, but the best and  worst seem more memorable, and that's only 1 more choice[^5].

And now, (stepping into the trap to show its allure, if you will), what if we
don't want to entirely change up our likelihood to handle the new rich source of data? So instead, we just treat the worsts
as the opposite of the bests, which makes a sort of sense, and simplifies the likelihood
one hell of a lot:

$$
U_{ij}^W = -U_{ij}^B = -(\mu_{ij} + \epsilon_{ij})
$$

Under this assumption, the probability of individual $i$ choosing alternative $j$ as the worst is:
$$
P_{ij}^W = \frac{\exp(-\mu_{ij})}{\sum_{k \in C_i} \exp(-\mu_{ik})}
$$

... Now we've stepped in it, and Jimmy is mad at us.

## Psycologically Incoherent

What I've introduced is the core of the MaxDiff formulation 

## Mathmatically Incorrect

# The defects are not theoretical or cosmetic: an illustration

# Alternative #1: rank-ordered logits with connected graphs of choices

# Alternative #2: a backup plan- rank-ordered logits with ties

# Stepping Back: the utility of discrete choice more broadly

[^1]: The smiley face is a threat: it's there to make sure MaxDiff stays down :-D
[^2]: If you want more of an in-depth introduction, here are some resources I'd reccomend. First, Jim Savage's [blog post series](https://khakieconomics.github.io/2019/03/17/Logit-models-of-discrete-choice.html) is great, and does a fantastic job of explaining how our assumptions about choice making map onto the math. I also benefitted from reading Glasgow's [Interpreting Discrete Choice Models](https://www.cambridge.org/core/elements/abs/interpreting-discrete-choice-models/676EC2C0F19A3B6D932E12CC612872BC), which builds up the basics of choice models a bit more slowly. Finally, if you want something that goes much more in detail, Kenneth Train's [Discrete Choice Models with Simulation](https://eml.berkeley.edu/books/choice2.html) goes into great mathmatical detail about the models.
[^3]: I won't rehash more subtle implications of this basic model here; see the footnote above for references that explore the mind of this **Homo Economicus** more in depth. Instead, I'll mostly pull up assumptions as they become relevant for discussing MaxDiff.
[^4]: Other options are possible, but less common, and would take us too far afield, so I'll skip explaining the choice of Gumbel versus other distriubtions here.