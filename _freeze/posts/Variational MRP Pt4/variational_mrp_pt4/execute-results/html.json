{
  "hash": "2e51e60032be9993d1ec131af0a12701",
  "result": {
    "markdown": "---\nlayout: post\ntitle: Variational Inference for MRP with Reliable Posterior Distributions\nsubtitle: Part 4- Some theory on why VI is hard\ndate: 2023-05-02\ndraft: True\ncategories:\n- MRP\n- Variational Inference\n---\n\n\nThis is section 4 in my series on using Variational Inference to speed up relatively complex Bayesian models like Multilevel Regression and Poststratification without the approximation being of disastrously poor quality. \n\nThe general structure for this post and the ones before and after it will be to describe a problem with VI, and then describe how that problem can be fixed to some degree. Collectively, all the small improvements in these three posts will go a long way towards more robust variational inference. I'll also have a grab bag at the end of other interesting ideas from the literature I think are cool, but maybe not as important or interesting to me as the 3 below.\n\nIn the [last post](https://andytimm.github.io/posts/Variational%20MRP%20Pt3/variational_mrp_3.html) we took a look at how our ELBO objective requires  specific version of KL Divergence (the \"Exclusive\" formulation of KLD), and saw that it encoded a preference for a certain type of solution to the VI problem. Then we looked at CUBO and CHIVI, an alternative bound and algorithm that avoid this problem, often leading to a more useful posterior distribution by pursuing a more \"inclusive\" solution.\n\nThe rough plan for the series is as follows:\n\n1.  Introducing the Problem- Why is VI useful, why VI can produce spherical cows\n2.  How far does iteration on classic VI algorithms like mean-field and full-rank get us?\n3.  Problem 1: KL-D prefers exclusive solutions; are there alternatives?\n4. **(This post)** Problem 2: Not all VI samples are of equal utility; can we weight them cleverly?\n5. Problem 3: How can we know when VI is wrong? Are there useful error bounds?\n5. Better grounded diagnostics and workflow\n6. Seeing if some more sophisticated techniques like normalizing flows add much\n\n# Not all samples are equally good\n\nSo we've made an approximation $q(x)$ that's cheap to sample from, and is somewhat\nclose to $p(x)$, our true posterior. The way to improve the approximation we've\nfocused on so far is to just go back to the start and make $q(x)$ better; for example,\nthrough changing up the variational family, or to switching to a different\noptimization objective like the CUBO. That's one solution that's often necessary,\nbut can we work with a particular $q(x)$ we have and make better use of the parts of it that are the closest to being right?\n\n... Phased this way, this sounds a lot like importance sampling. If you haven't seen them before,\nan importance sampling estimator allows us to take draws from a (preferably) easy to sample\nfrom distribution[^7] and reweight the samples to look more like our true target\ndistribution. The weight $w_i$ for each sample $i$ take form:\n\n$$\nw_i = \\frac{p(x_i)}{q(x_i)}\n$$\nBefore you get worried that we don't have $p(x_i)$ because of the normalizing constant like every time we talk about having $p(x)$ in this series, there's a clever estimator that\n\"self-normalizes\" such that this can be a reasonable strategy. Intuitively, we're\njust placing more weight on samples in the support of $p(x)$.\n\nThis footenote[^8] has a selection of some of my favorite resources for learning more or refreshing your memory about importance sampling, but for the main discussion let me pull out some\nparticularly important sub-problems to solve in making a good importance sampling estimator, and good important sampling estimator for VI. \n\nFirst, our choice of the \"proposal\" distribution we're reweighting to be more like\n$p(x)$ matters for making this process practically feasible. We need the proposal\ndistribution to be close enough to $p(x)$ that a realistic number of the draws\nget non-negligible weights.\nIt might be true that we could draw proposals from a big $N$ dimensional uniform\ndistribution for every problem, but if we want to be done sampling enough this century\nwe need to at least get fairly close with our initial $q(x)$.\n\nA second, but related problem is that it's quite common for the unmodified\nimportance sampling estimator to have some weights which are orders and orders\nof magnitude higher than the average weight, blowing up the variance of the estimator.\nDan Simpson's slides I linked above has an instructive example with not too\nweird $p(x)$ and $q(x)$'s that has a max weight ~1.4 million (!) times the average.\nIf that happens, our estimator will essentially ignore most samples without gigantic\nweights, and it'll take ages for that estimator to tell us anything remotely\nreliable. \n\nSo with those points we need to address, here are the next topics in this post:\n\n1. Importance Weighted Variational Inference\n2. Robust importance sampling with built in diagnostics via PSIS\n3. Combining multiple proposal distributions via Multiple Importance Sampling\n\n\n## Importance Weighted Variational Inference\n\nThe actual use of Importance Weighting for VI in it's simplest form is\npretty intuitive (draw samples from $q(x)$, weight them...), but let's derive the\nnew Importance Weighted Variational Inference (IWVI) estimator since some nice\nintuition will come with it.\n\nWe'll aim to show that we can get a tighter ELBO by using importance weights. This\ntype of tighter ELBO was first shown by [Burda et Al. (2015)](https://arxiv.org/abs/1509.00519)\nin the context of Variational Autoencoders after which is was fairly clear this could apply\nto variational inference, but [Domke and Sheldon (2018)](https://arxiv.org/abs/1808.09034)\nfleshed out some details of that extension- I'll be explaining some of the latter group's main\nresults first.\n\nTo start, imagine a random variable $R$, such that $\\mathbb{E}{R} = p(x)$, which\nwe'll think of as a estimator of p(x). Then by Jensen's Inequality:\n\n$$\nlogp(x) = \\mathbb{E}logR + \\mathbb{E}log\\frac{p(x)}{R}\n$$\n\nThe first term is the bound, which will be tighter if $R$ is highly concentrated. \n\nThis is a more general form of the ELBO; we can make it quite familiar looking by\nhaving our R above be:\n\n$$\nR = \\frac{p(z,x)}{q(z)}, z \\sim q\n$$\n\nThe reason pointing out this fairly simple generalization is helpful is that it\nframes how to tighten our ELBO bound on $logp(x)$ via alternative estimators $R$.\n\nBy drawing $M$ samples and averaging them as in importance sampling, we get:\n\n$$\nR_M = \\frac{1}{M}\\sum_{m=1}^{M}\\frac{p(z_m,x)}{q(z_m)}, z_m \\sim q\n$$\nFrom there, we can derive a tighter bound on $logp(x)$, referred to as the IW-ELBO:\n\n$$\nIW-ELBO_M[q(z)||p(z,x)] := \\mathbb{E}_{q(z_{1:M})}log\\frac{1}{M} \\sum_{m=1}^{M}\\frac{p(z_m,x)}{q(z_m)}\n$$\nWhere we're using the $1:M$ as a shorthand for eg $q(z_{1:M}) = q(z_1)...q(z_M)$.\n\n\nIt's worth noting that the last few lines don't specify a particular form of importance\nsampling- we're getting the tighter theoretical bounding behavior from the averaging of samples\nfrom $q$. We'll see a particularly good form of importance sampling with desirable\npractical properties in a moment.\n\n### How does IW-ELBO change the VI problem conceptually?\n\nThe tighter bound is nice, but importance sampling also has the side effect (done right, side benefit)\nof modifying our incentives in choosing a variational family. To see what I mean,\nwe can re-use the example distributions from last post we used to build intuition for KL Divergence, where red was the true distribution,\nand green were our potential approximations. If we're not going to draw multiple samples and weight them, it makes sense to choose something like the first plot below. Every draw in the middle of the two target modes\nis expensive per our ELBO objective, so better to choose a mode.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrkl_plot <- mixture %>% ggplot(aes(x = normals)) +\n  geom_density(aes(x = normals), color = \"red\") +\n  geom_density(aes(x = mode_seeking_kl), color = \"green\") + ggtitle(\"Without weighting, we prefer to capture a mode\") +\n  xlab(\"\")\n\nfkl_plot <- mixture %>% ggplot(aes(x = normals)) +\n  geom_density(aes(x = normals), color = \"red\") +\n  geom_density(aes(x = mean_seeking_kl), color = \"green\") + ggtitle(\"With importance sampling, weights allow us to prefer coverage\") +\n  xlab(\"\")\n\ngrid.arrange(rkl_plot,fkl_plot)\n```\n\n::: {.cell-output-display}\n![](variational_mrp_pt4_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nIf we can use importance samples though, quite the opposite is be true! Note that we're\nstill using the ELBO, a reverse-KL based metric- that hasn't changed. What has changed is our\nability to mitigate the objective costs of those samples between the two extremes.\nPoints outside the two target modes will get lower importance weights, and points within\nthe modes will get higher ones, so as long as we're covering the modes with some reasonable amount of probability mass, and drawing enough samples we can actually\ndo better with the distribution centered between the modes. \n\nWe can also imagine how varying the number of samples might effect the point\nfrom the last paragraph. Between $M=1$ and \"enough draws to get all the benefits of IS\",\nwe can imagine there's a slow transition from \"just stick with 1 mode\" and \"go with IS\".\nSo it seems like we should be worried about getting the number of samples right, but\nfortunately as we'll see in the next section there are great rules of thumb in\nsome variants of IS. We'll still need to bear the cost of sampling (which gets higher as $q(x)$ becomes \"further\" from $p(x)$, as we'll need more samples to weight into a good approximation), but\nthe cost of sampling for most VI implementations will often be pretty manageable\nif our proposal distribution is somewhat close to $p(x)$.\n\nAnother way to think about how importance sampling changes our task with variational\ninference is to think about what sorts of distributions make sense to have as\nour variational family, and even which objective might be better given IS. On choice\nof a variational family, if we're aiming for coverage, moving towards thicker-tailed distributions like t distributions makes a lot of sense. While we explored\nthe IW-ELBO above to build intuition, there's no reason not to apply VI to the CUBO\n and thus CHIVI- this also naturally produces nicely overdispersed distributions which can\n be importance sampled closer to the true $p(x)$. This idea of aiming for a\n wide proposal to sample from is referred to in the importance sampling literature (eg [Owen, 2013](https://artowen.su.domains/mc/)) as \"defensive sampling\", with [Domke and Sheldon (2018)](https://arxiv.org/abs/1808.09034) exploring the VI connection more fully. For intuition, by ensuring most of p(x) is covered by some reasonable mass makes it easier to efficiently\n get draws that can be weighted into a final posterior, even if the unweighted\n posterior might be too wide.\n\n## Solving our IS problems with Pareto-Smoothed Importance Sampling\n\nAs we've been talking about importance sampling, we've been leaving some of the\nmessier details aside (how many samples to draw, how to deal with the cases when some\nof the weights get huge, how to know when our proposal distribution is \"close\" enough).\n\nWhile the Importance Sampling Literature is huge and there are a lot of possible\nsolutions here, I'll next introduce [Vehtari et Al. (2015)](https://arxiv.org/abs/1507.02646)'s Pareto-Smoothed Importance Sampling. I'm a huge fan of this paper, and it's\namongst the coolest things I got to study in grad school. \n\nThe core idea here as I started to describe above is that  \n\n## Multiple Proposal Distributions with Multiple Importance Sampling\n\n# Can we bound error in terms of ELBO or CUBO?\n\n## Wasserstein Bounds\n\n# Conclusions + Bonus Context\n\n\n[^7]: we'll call it q(x) here to make the application super clear, but often\nI see the \"proposal\" distribution called f(x) and the the distribution we want\nto approximate called g(x). \n[^8]: If you're looking to learn about importance sampling for the first time,\na great place to start is Ben Lambert's video introductions to the basic idea:\n[video 1](https://www.youtube.com/watch?v=V8f8ueBc9sY), and [video 2](https://www.youtube.com/watch?v=F5PdIQxMA28). For building more intuition about\nwhy we need all these variance reducing modifications to general IS, Dan Simpson\nhas some great [slides](https://dpsimpson.github.io/pages/talks/Importance_sampling_unsw_2019.pdf) which have a side benefit of being hilarious. Those slides will mention a lot of the books/papers\nI find most instructive, but it's worth calling out especially Vehtari et Al's Pareto Smoothed\nImportance Sampling [paper](https://arxiv.org/abs/1507.02646) as particularly\nwell written and paradigm shaping. Finally, Elvira et Al's (2019) Multiple Importance Sampling\n[paper](https://projecteuclid.org/journals/statistical-science/volume-34/issue-1/Generalized-Multiple-Importance-Sampling/10.1214/18-STS668.full) is the most thorough I know, but isn't particularly approachable. Instead, for MIS I'd recommend starting with the first few minutes of [this talk](https://www.youtube.com/watch?v=dxFSwplfdpk) (although the main topic of their talk is less relevant, the visualizations are super helpful), and the first ~8 pages of [this paper](https://arxiv.org/pdf/2102.05407.pdf), also by Elvira et Al. (2021) (I especially like\nthat it spends a bit more time on notation; since multiple importance sampling comes from/comes up\nin computer graphics, the notational choices sometimes feel a bit annoying to me). Finally,\nthe [original MIS paper itself](https://dl.acm.org/doi/10.1145/218380.218498), Veach & Guibas (1995) is quite readable, but requires\na bit of reading around or reading into computer graphics to grok their examples\nand notational choices. ",
    "supporting": [
      "variational_mrp_pt4_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}